{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1k6Y9afpxL6"
   },
   "source": [
    "# Intro\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a very powerful machine learning framework. Central to PyTorch are [tensors](https://pytorch.org/docs/stable/tensors.html), a generalization of matrices to higher ranks. One intuitive example of a tensor is an image with three color channels: A 3-channel (red, green, blue) image which is 64 pixels wide and 64 pixels tall is a $3\\times64\\times64$ tensor. You can access the PyTorch framework by writing `import torch` near the top of your code, along with all of your other import statements.\n",
    "\n",
    "This guide will help introduce you to the functionality of PyTorch, but don't worry too much about memorizing it: the assignments will link to relevant documentation where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwp6T5ZMteDC"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvXp0rlPBqdQ"
   },
   "source": [
    "# Why PyTorch?\n",
    "\n",
    "One important question worth asking is, why is PyTorch being used for this course? There is a great breakdown by [the Gradient](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) looking at the state of machine learning frameworks today. In part, as highlighted by the article, PyTorch is generally more pythonic than alternative frameworks, easier to debug, and is the most-used language in machine learning research by a large and growing margin. While PyTorch's primary alternative, Tensorflow, has attempted to integrate many of PyTorch's features, Tensorflow's implementations come with some inherent limitations highlighted in the article.\n",
    "\n",
    "Notably, while PyTorch's industry usage has grown, Tensorflow is still (for now) a slight favorite in industry. In practice, the features that make PyTorch attractive for research also make it attractive for education, and the general trend of machine learning research and practice to PyTorch makes it the more proactive choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCgwdP20r1yX"
   },
   "source": [
    "# Tensor Properties\n",
    "One way to create tensors from a list or an array is to use `torch.Tensor`. It'll be used to set up examples in this notebook, but you'll never need to use it in the course - in fact, if you find yourself needing it, that's probably not the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0hgYekGsxlB"
   },
   "outputs": [],
   "source": [
    "example_tensor = torch.Tensor(\n",
    "    [\n",
    "     [[1, 2], [3, 4]], \n",
    "     [[5, 6], [7, 8]], \n",
    "     [[9, 0], [1, 2]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dO4C2oft7zq"
   },
   "source": [
    "You can view the tensor in the notebook by simple printing it out (though some larger tensors will be cut off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "U2FKEzeYuEOX",
    "outputId": "dfa12ff7-afd1-4737-a669-54f36b4209dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[9., 0.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUwlmUngw-VR"
   },
   "source": [
    "## Tensor Properties: Device\n",
    "\n",
    "One important property is the device of the tensor - throughout this notebook you'll be sticking to tensors which are on the CPU. However, throughout the course you'll also be using tensors on GPU (that is, a graphics card which will be provided for you to use for the course). To view the device of the tensor, all you need to write is `example_tensor.device`. To move a tensor to a new device, you can write `new_tensor = example_tensor.to(device)` where device will be either `cpu` or `cuda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R7SF44_Vw9h0",
    "outputId": "57f90e38-f9e1-4115-8f27-ebe651d5b2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkfySyFduHQi"
   },
   "source": [
    "## Tensor Properties: Shape\n",
    "\n",
    "And you can get the number of elements in each dimension by printing out the tensor's shape, using `example_tensor.shape`, something you're likely familiar with if you've used numpy. For example, this tensor is a $3\\times2\\times2$ tensor, since it has 3 elements, each of which are $2\\times2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DKmfzpOBun0t",
    "outputId": "883009b6-7300-4329-f9ec-df99cc36d846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aL954xmAuq4b"
   },
   "source": [
    "You can also get the size of a particular dimension $n$ using `example_tensor.shape[n]` or equivalently `example_tensor.size(n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7IKy3BB8uqBo",
    "outputId": "7fac1275-132f-4d2b-bf63-73065a2aea6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape[0] = 3\n",
      "size(1) = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"shape[0] =\", example_tensor.shape[0])\n",
    "print(\"size(1) =\", example_tensor.size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pzzG8bav5rl"
   },
   "source": [
    "Finally, it is sometimes useful to get the number of dimensions (rank) or the number of elements, which you can do as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l_j9qTwyv41-",
    "outputId": "5921cbd1-19a2-4543-9488-3f72c0cb4970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank = 3\n",
      "Number of elements = 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank =\", len(example_tensor.shape))\n",
    "print(\"Number of elements =\", example_tensor.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gibyKQJQzLkm"
   },
   "source": [
    "# Indexing Tensors\n",
    "\n",
    "As with numpy, you can access specific elements or subsets of elements of a tensor. To access the $n$-th element, you can simply write `example_tensor[n]` - as with Python in general, these dimensions are 0-indexed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F87bFA5SzNz7",
    "outputId": "1b0a8381-6fd8-40b4-a5c8-88cc80029f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CegGw5wzpGa"
   },
   "source": [
    "In addition, if you want to access the $j$-th dimension of the $i$-th example, you can write `example_tensor[i, j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bl1JSZcRz0xn",
    "outputId": "7f98e47b-66cb-4927-b784-7e4bcb9eb687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyQRCRIa4NaY"
   },
   "source": [
    "Note that if you'd like to get a Python scalar value from a tensor, you can use `example_scalar.item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e56KSJOq4YOE",
    "outputId": "29e1fd13-32df-40c5-e558-3193fa5da629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZdMEQfu0A7h"
   },
   "source": [
    "In addition, you can index into the ith element of a column by using `x[:, i]`. For example, if you want the top-left element of each element in `example_tensor`, which is the `0, 0` element of each matrix, you can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x2cFxJx50eGH",
    "outputId": "e66eade9-4b4b-4c7a-ea99-a83195d10541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-rTBP-1whd2"
   },
   "source": [
    "# Initializing Tensors\n",
    "\n",
    "There are many ways to create new tensors in PyTorch, but in this course, the most important ones are: \n",
    "\n",
    "[`torch.ones_like`](https://pytorch.org/docs/master/generated/torch.ones_like.html): creates a tensor of all ones with the same shape and device as `example_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "g7gbs4AnwlIo",
    "outputId": "b0c67ed9-e33f-47d6-d95c-e53bc4f90dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aIbSlaJy9Z0"
   },
   "source": [
    "[`torch.zeros_like`](https://pytorch.org/docs/master/generated/torch.zeros_like.html): creates a tensor of all zeros with the same shape and device as `example_tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "X4cWQduzzCd8",
    "outputId": "dbc8a5fa-8db1-4f6d-e38e-d1deb982ff36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsOmgS1izDS_"
   },
   "source": [
    "[`torch.randn_like`](https://pytorch.org/docs/stable/generated/torch.randn_like.html): creates a tensor with every element sampled from a [Normal (or Gaussian) distribution](https://en.wikipedia.org/wiki/Normal_distribution) with the same shape and device as `example_tensor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2hto51IazDow",
    "outputId": "cb62a68a-6171-4d1e-eb9b-f31784464aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1212, -0.9564],\n",
       "         [ 1.0508,  0.7532]],\n",
       "\n",
       "        [[ 1.9562, -0.5611],\n",
       "         [ 0.8843,  0.0194]],\n",
       "\n",
       "        [[-0.7667,  1.3042],\n",
       "         [ 1.8819,  0.7251]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXp0i5Cf6AGj"
   },
   "source": [
    "Sometimes (though less often than you'd expect), you might need to initialize a tensor knowing only the shape and device, without a tensor for reference for `ones_like` or `randn_like`. In this case, you can create a $2x2$ tensor as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RZRqt3-S6cUZ",
    "outputId": "7bef97cc-a303-4200-c0f8-ef9bf3cb4996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3150, -0.6664],\n",
       "        [-0.1546, -0.8158]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 2, device='cpu') # Alternatively, for a GPU tensor, you'd use device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTkmDwVsrM6R"
   },
   "source": [
    "# Basic Functions\n",
    "\n",
    "There are a number of basic functions that you should know to use PyTorch - if you're familiar with numpy, all commonly-used functions exist in PyTorch, usually with the same name. You can perform element-wise multiplication / division by a scalar $c$ by simply writing `c * example_tensor`, and element-wise addition / subtraction by a scalar by writing `example_tensor + c`\n",
    "\n",
    "Note that most operations are not in-place in PyTorch, which means that they don't change the original variable's data (However, you can reassign the same variable name to the changed data if you'd like, such as `example_tensor = example_tensor + 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "FpfwOUdopsF_",
    "outputId": "32347400-2e6a-40c6-e6f1-21e6aacde795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -8.,  -6.],\n",
       "         [ -4.,  -2.]],\n",
       "\n",
       "        [[  0.,   2.],\n",
       "         [  4.,   6.]],\n",
       "\n",
       "        [[  8., -10.],\n",
       "         [ -8.,  -6.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example_tensor - 5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uciZnx4b3UjX"
   },
   "source": [
    "You can calculate the mean or standard deviation of a tensor using [`example_tensor.mean()`](https://pytorch.org/docs/stable/generated/torch.mean.html) or [`example_tensor.std()`](https://pytorch.org/docs/stable/generated/torch.std.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0ELXUKG7329z",
    "outputId": "720dd190-7dd4-43f1-e53c-cba4263eb2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(4.)\n",
      "Stdev: tensor(2.9848)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", example_tensor.mean())\n",
    "print(\"Stdev:\", example_tensor.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QsyTRym32SX"
   },
   "source": [
    "You might also want to find the mean or standard deviation along a particular dimension. To do this you can simple pass the number corresponding to that dimension to the function. For example, if you want to get the average $2\\times2$ matrix of the $3\\times2\\times2$ `example_tensor` you can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eCJl3Im25B9k",
    "outputId": "4bd9decd-579e-462c-bde1-ee8d9d1b2061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 2.6667],\n",
       "        [3.6667, 4.6667]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.mean(0)\n",
    "\n",
    "# Equivalently, you could also write:\n",
    "# example_tensor.mean(dim=0)\n",
    "# example_tensor.mean(axis=0)\n",
    "# torch.mean(example_tensor, 0)\n",
    "# torch.mean(example_tensor, dim=0)\n",
    "# torch.mean(example_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb-_5ubc8t97"
   },
   "source": [
    "PyTorch has many other powerful functions but these should be all of PyTorch functions you need for this course outside of its neural network module (`torch.nn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtWjExD69JEs"
   },
   "source": [
    "# PyTorch Neural Network Module (`torch.nn`)\n",
    "\n",
    "PyTorch has a lot of powerful classes in its `torch.nn` module (Usually, imported as simply `nn`). These classes allow you to create a new function which transforms a tensor in specific way, often retaining information when called multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYrgloYo_slC"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyCPVmTD_kkl"
   },
   "source": [
    "## `nn.Linear`\n",
    "\n",
    "To create a linear layer, you need to pass it the number of input dimensions and the number of output dimensions. The linear object initialized as `nn.Linear(10, 2)` will take in a $n\\times10$ matrix and return an $n\\times2$ matrix, where all $n$ elements have had the same linear transformation performed. For example, you can initialize a linear layer which performs the operation $Ax + b$, where $A$ and $b$ are initialized randomly when you generate the [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pNPaHPo89VrN",
    "outputId": "c14dc316-ae68-49d3-a8eb-8ad6e1464f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3066,  0.3297],\n",
       "        [-0.0424,  0.1532],\n",
       "        [ 0.0383, -0.1404]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 2)\n",
    "example_input = torch.randn(3, 10)\n",
    "example_output = linear(example_input)\n",
    "example_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGNULkJR_mzn"
   },
   "source": [
    "## `nn.ReLU`\n",
    "\n",
    "[`nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) will create an object that, when receiving a tensor, will perform a ReLU activation function. This will be reviewed further in lecture, but in essence, a ReLU non-linearity sets all negative numbers in a tensor to zero. In general, the simplest neural networks are composed of series of linear transformations, each followed by activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nGxVFS3nBASc",
    "outputId": "d5f57584-1bad-4803-ba8c-b69881db4a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3297],\n",
       "        [0.0000, 0.1532],\n",
       "        [0.0383, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu_output = relu(example_output)\n",
    "relu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzfOEZ03AJzA"
   },
   "source": [
    "## `nn.BatchNorm1d`\n",
    "\n",
    "[`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) is a normalization technique that will rescale a batch of $n$ inputs to have a consistent mean and standard deviation between batches.  \n",
    "\n",
    "As indicated by the `1d` in its name, this is for situations where you expects a set of inputs, where each of them is a flat list of numbers. In other words, each input is a vector, not a matrix or higher-dimensional tensor. For a set of images, each of which is a higher-dimensional tensor, you'd use [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), discussed later on this page.\n",
    "\n",
    "`nn.BatchNorm1d` takes an argument of the number of input dimensions of each object in the batch (the size of each example vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "O4tYsi9-G9vM",
    "outputId": "ba61d37c-a8af-4663-fcc2-1691c6d241de",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6965,  1.2522],\n",
       "        [-0.6965, -0.0576],\n",
       "        [ 1.3930, -1.1946]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchnorm = nn.BatchNorm1d(2)\n",
    "batchnorm_output = batchnorm(relu_output)\n",
    "batchnorm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMZewDz9Idr1"
   },
   "source": [
    "## `nn.Sequential`\n",
    "\n",
    "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) creates a single operation that performs a sequence of operations. For example, you can write a neural network layer with a batch normalization as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "R3GhASjyJt3N",
    "outputId": "3ef779ca-a17b-42fd-f2e5-fbb5fdc60b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "tensor([[ 3.0064,  1.2974,  0.0238,  1.1194,  1.2301],\n",
      "        [ 1.2429,  2.0650,  1.5826,  3.0315,  0.4943],\n",
      "        [ 2.0930,  0.9832,  0.6951, -0.8614,  0.9691],\n",
      "        [ 1.6045,  1.7765, -0.0591,  0.6480, -0.9884],\n",
      "        [ 1.1689,  1.2136,  2.5438,  2.2091,  2.1822]])\n",
      "output: \n",
      "tensor([[0.8386, 0.2292],\n",
      "        [0.0729, 0.8468],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [1.1538, 1.2178]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp_layer = nn.Sequential(\n",
    "    nn.Linear(5, 2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "test_example = torch.randn(5,5) + 1\n",
    "print(\"input: \")\n",
    "print(test_example)\n",
    "print(\"output: \")\n",
    "print(mlp_layer(test_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SToQiSv5K5Yb"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "One of the most important aspects of essentially any machine learning framework is its automatic differentiation library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4GZFCZ0QqI1"
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "To create an optimizer in PyTorch, you'll need to use the `torch.optim` module, often imported as `optim`. [`optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) corresponds to the Adam optimizer. To create an optimizer object, you'll need to pass it the parameters to be optimized and the learning rate, `lr`, as well as any other parameters specific to the optimizer.\n",
    "\n",
    "For all `nn` objects, you can access their parameters as a list using their `parameters()` method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcCbs35K4wY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "adam_opt = optim.Adam(mlp_layer.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BsPFZu2M0Xx"
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "A (basic) training step in PyTorch consists of four basic parts:\n",
    "\n",
    "\n",
    "1.   Set all of the gradients to zero using `opt.zero_grad()`\n",
    "2.   Calculate the loss, `loss`\n",
    "3.   Calculate the gradients with respect to the loss using `loss.backward()`\n",
    "4.   Update the parameters being optimized using `opt.step()`\n",
    "\n",
    "That might look like the following code (and you'll notice that if you run it several times, the loss goes down):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a9dbbc978980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_example' is not defined"
     ]
    }
   ],
   "source": [
    "print(mlp_layer(train_example).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zm6lPx4sOJht",
    "outputId": "c21672bd-a306-42ab-face-9a299511a059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=  0.7572625875473022\n",
      "mean pred=  0.4149680733680725\n"
     ]
    }
   ],
   "source": [
    "train_example = torch.randn(100,5) + 1\n",
    "adam_opt.zero_grad()\n",
    "\n",
    "# We'll use a simple loss function of mean distance from 1\n",
    "# torch.abs takes the absolute value of a tensor\n",
    "cur_loss = torch.abs(1 - mlp_layer(train_example)).mean()\n",
    "\n",
    "cur_loss.backward()\n",
    "adam_opt.step()\n",
    "print('loss= ',cur_loss.item())\n",
    "print('mean pred= ', mlp_layer(train_example).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "tensor([0.2491, 0.4900])\n",
      "tensor([0.8042, 0.8648])\n",
      "Parameter containing:\n",
      "tensor([0.9000, 0.9000], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1000, 0.1000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "bn2 = mlp_layer[1]\n",
    "print(bn2.momentum)\n",
    "print(bn2.running_mean)\n",
    "print(bn2.running_var)\n",
    "print(bn2.weight)\n",
    "print(bn2.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDjhZBCeTc6o"
   },
   "source": [
    "## `requires_grad_()`\n",
    "\n",
    "You can also tell PyTorch that it needs to calculate the gradient with respect to a tensor that you created by saying `example_tensor.requires_grad_()`, which will change it in-place. This means that even if PyTorch wouldn't normally store a grad for that particular tensor, it will for that specified tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mB22ovHyUEvH"
   },
   "source": [
    "## `with torch.no_grad():`\n",
    "\n",
    "PyTorch will usually calculate the gradients as it proceeds through a set of operations on tensors. This can often take up unnecessary computations and memory, especially if you're performing an evaluation. However, you can wrap a piece of code with `with torch.no_grad()` to prevent the gradients from being calculated in a piece of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kowb1M425CE_"
   },
   "source": [
    "\n",
    "## `detach():`\n",
    "\n",
    "Sometimes, you want to calculate and use a tensor's value without calculating its gradients. For example, if you have two models, A and B, and you want to directly optimize the parameters of A with respect to the output of B, without calculating the gradients through B, then you could feed the detached output of B to A. There are many reasons you might want to do this, including efficiency or cyclical dependencies (i.e. A depends on B depends on A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9HY2wgKLOr-"
   },
   "source": [
    "# New `nn` Classes\n",
    "\n",
    "You can also create new classes which extend the `nn` module. For these classes, all class attributes, as in `self.layer` or `self.param` will automatically treated as parameters if they are themselves `nn` objects or if they are tensors wrapped in `nn.Parameter` which are initialized with the class. \n",
    "\n",
    "The `__init__` function defines what will happen when the object is created. The first line of the init function of a class, for example, `WellNamedClass`, needs to be `super(WellNamedClass, self).__init__()`. \n",
    "\n",
    "The `forward` function defines what runs if you create that object `model` and pass it a tensor `x`, as in `model(x)`. If you choose the function signature, `(self, x)`, then each call of the forward function, gets two pieces of information: `self`, which is a reference to the object with which you can access all of its parameters, and `x`, which is the current tensor for which you'd like to return `y`.\n",
    "\n",
    "One class might look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOip473tQs-d"
   },
   "outputs": [],
   "source": [
    "class ExampleModule(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(ExampleModule, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_dims)\n",
    "        self.exponent = nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # This is the notation for element-wise exponentiation, \n",
    "        # which matches python in general\n",
    "        x = x ** self.exponent \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4CUFH_GS5UY"
   },
   "source": [
    "And you can view its parameters as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YuelIiE4S3KR",
    "outputId": "27a52620-ca40-4dc8-dff5-4f3a56ba0e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor(1., requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2713,  0.2671, -0.1566,  0.3014,  0.0366,  0.0370,  0.2419,  0.2567,\n",
       "          -0.0135, -0.2507],\n",
       "         [ 0.1538, -0.0921, -0.0921,  0.0208, -0.1309,  0.0814, -0.1973, -0.1937,\n",
       "           0.1678,  0.3116]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1461, -0.0995], requires_grad=True)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model = ExampleModule(10, 2)\n",
    "list(example_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F7E1wKN5tez"
   },
   "source": [
    "And you can print out their names too, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "dYTuTDsQ5pnY",
    "outputId": "6635a493-7318-4688-bd18-bfba41d43e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exponent',\n",
       "  Parameter containing:\n",
       "  tensor(1., requires_grad=True)),\n",
       " ('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2713,  0.2671, -0.1566,  0.3014,  0.0366,  0.0370,  0.2419,  0.2567,\n",
       "           -0.0135, -0.2507],\n",
       "          [ 0.1538, -0.0921, -0.0921,  0.0208, -0.1309,  0.0814, -0.1973, -0.1937,\n",
       "            0.1678,  0.3116]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1461, -0.0995], requires_grad=True))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example_model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWPoIqX2UsaH"
   },
   "source": [
    "And here's an example of the class in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7NXwbg5tUroC",
    "outputId": "0836e447-7c37-464e-b196-048ae0a0cc73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2826,  0.1715],\n",
       "        [-0.0986,  0.2645]], grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 10)\n",
    "example_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ocol8DABScy"
   },
   "source": [
    "# 2D Operations\n",
    "\n",
    "You won't need these for the first lesson, and the theory behind each of these will be reviewed more in later lectures, but here is a quick reference: \n",
    "\n",
    "\n",
    "*   2D convolutions: [`nn.Conv2d`](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html) requires the number of input and output channels, as well as the kernel size.\n",
    "*   2D transposed convolutions (aka deconvolutions): [`nn.ConvTranspose2d`](https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html) also requires the number of input and output channels, as well as the kernel size\n",
    "*   2D batch normalization: [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) requires the number of input dimensions\n",
    "*   Resizing images: [`nn.Upsample`](https://pytorch.org/docs/master/generated/torch.nn.Upsample.html) requires the final size or a scale factor. Alternatively, [`nn.functional.interpolate`](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.interpolate) takes the same arguments. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import\n",
    "* make tensor from list\n",
    "    * check shape\n",
    "    * check device\n",
    "* indexing\n",
    "* init ones_like, randn_like\n",
    "* use in basic functions (add, mult, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = torch.tensor([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list[0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = torch.ones_like(t_list)\n",
    "t_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_zeros = torch.zeros_like(t_list)\n",
    "t_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7, 86],\n",
       "         [83, 39]],\n",
       "\n",
       "        [[39, 26],\n",
       "         [61, 22]],\n",
       "\n",
       "        [[38, 78],\n",
       "         [10, 11]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randint = torch.randint_like(t_list, low=0, high=99)\n",
    "t_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float = t_list.float()\n",
    "t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9454, 0.0895],\n",
       "         [0.5591, 0.8790]],\n",
       "\n",
       "        [[0.0400, 0.0909],\n",
       "         [0.9680, 0.3886]],\n",
       "\n",
       "        [[0.7130, 0.0811],\n",
       "         [0.6781, 0.5874]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rand = torch.rand_like(t_list_float)\n",
    "t_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7170, -0.5156],\n",
       "         [-0.2708, -1.7794]],\n",
       "\n",
       "        [[-0.8899, -1.8661],\n",
       "         [-0.3738, -0.0905]],\n",
       "\n",
       "        [[ 1.0038,  1.6794],\n",
       "         [-0.2170, -0.3778]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randn = torch.randn_like(t_list_float)\n",
    "t_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  4.],\n",
       "         [ 6.,  8.]],\n",
       "\n",
       "        [[10., 12.],\n",
       "         [14., 16.]],\n",
       "\n",
       "        [[18., 20.],\n",
       "         [22., 24.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9]],\n",
       "\n",
       "        [[10, 11],\n",
       "         [12, 13]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float + t_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  3.],\n",
       "         [ 4.,  5.]],\n",
       "\n",
       "        [[ 6.,  7.],\n",
       "         [ 8.,  9.]],\n",
       "\n",
       "        [[10., 11.],\n",
       "         [12., 13.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float + t_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9454,  2.0895],\n",
       "         [ 3.5591,  4.8790]],\n",
       "\n",
       "        [[ 5.0400,  6.0909],\n",
       "         [ 7.9680,  8.3886]],\n",
       "\n",
       "        [[ 9.7130, 10.0811],\n",
       "         [11.6781, 12.5874]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8, 88],\n",
       "         [86, 43]],\n",
       "\n",
       "        [[44, 32],\n",
       "         [68, 30]],\n",
       "\n",
       "        [[47, 88],\n",
       "         [21, 23]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2830,  1.4844],\n",
       "         [ 2.7292,  2.2206]],\n",
       "\n",
       "        [[ 4.1101,  4.1339],\n",
       "         [ 6.6262,  7.9095]],\n",
       "\n",
       "        [[10.0038, 11.6794],\n",
       "         [10.7830, 11.6222]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   4.],\n",
       "         [  9.,  16.]],\n",
       "\n",
       "        [[ 25.,  36.],\n",
       "         [ 49.,  64.]],\n",
       "\n",
       "        [[ 81., 100.],\n",
       "         [121., 144.]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list * t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -0.7170,  -1.0312],\n",
       "         [ -0.8124,  -7.1177]],\n",
       "\n",
       "        [[ -4.4495, -11.1965],\n",
       "         [ -2.6168,  -0.7243]],\n",
       "\n",
       "        [[  9.0340,  16.7940],\n",
       "         [ -2.3871,  -4.5332]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list * t_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1,   4],\n",
       "         [  9,  16]],\n",
       "\n",
       "        [[ 25,  36],\n",
       "         [ 49,  64]],\n",
       "\n",
       "        [[ 81, 100],\n",
       "         [121, 144]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   4.],\n",
       "         [  9.,  16.]],\n",
       "\n",
       "        [[ 25.,  36.],\n",
       "         [ 49.,  64.]],\n",
       "\n",
       "        [[ 81., 100.],\n",
       "         [121., 144.]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_zeros **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9, 9],\n",
       "         [9, 9]],\n",
       "\n",
       "        [[9, 9],\n",
       "         [9, 9]],\n",
       "\n",
       "        [[9, 9],\n",
       "         [9, 9]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_ones+2) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6462,  2.2035],\n",
       "         [ 2.9902,  0.0487]],\n",
       "\n",
       "        [[ 1.2323,  0.0179],\n",
       "         [ 2.6444,  3.6460]],\n",
       "\n",
       "        [[ 9.0227, 13.5380],\n",
       "         [ 3.1791,  2.6316]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_randn+2) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5141, 0.2658],\n",
       "         [0.0733, 3.1663]],\n",
       "\n",
       "        [[0.7919, 3.4823],\n",
       "         [0.1397, 0.0082]],\n",
       "\n",
       "        [[1.0076, 2.8204],\n",
       "         [0.0471, 0.1427]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_randn) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_zeros.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5017)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rand.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41.6667)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randint.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3679)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6056)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3548)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9925)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randn.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 7.5000])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float.mean([0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = nn.BatchNorm1d(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.cat((torch.randn((1000,2,2))*2 + 4, torch.randn((1000,2,2))*10 + 1000), dim=1)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=  tensor(501.9691)\n",
      "std=  tensor(498.0547)\n",
      "var=  tensor(248058.5000)\n",
      "mean[:,half]= tensor([[   3.9793,    4.0487],\n",
      "        [   3.9663,    3.9914],\n",
      "        [1000.0323,  999.4709],\n",
      "        [ 999.7770, 1000.4872]])\n",
      "std[:,half]= tensor([[ 2.0153,  1.9064],\n",
      "        [ 1.9644,  2.0318],\n",
      "        [ 9.7743, 10.0047],\n",
      "        [ 9.8067,  9.8677]])\n",
      "var[:,half]= tensor([[  4.0614,   3.6343],\n",
      "        [  3.8590,   4.1282],\n",
      "        [ 95.5367, 100.0944],\n",
      "        [ 96.1718,  97.3715]])\n"
     ]
    }
   ],
   "source": [
    "print('mean= ',inp.mean())\n",
    "print('std= ',inp.std())\n",
    "print('var= ',inp.var())\n",
    "print('mean[:,half]=', inp.mean(0))\n",
    "print('std[:,half]=', inp.std(0))\n",
    "print('var[:,half]=', inp.var(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_bn1.size= torch.Size([1000, 4, 2])\n",
      "mean=  tensor(3.0708e-07, grad_fn=<MeanBackward0>)\n",
      "std=  tensor(1.0001, grad_fn=<StdBackward0>)\n",
      "mean[:,half]= tensor([[-0.0177,  0.0177],\n",
      "        [-0.0063,  0.0063],\n",
      "        [ 0.0284, -0.0284],\n",
      "        [-0.0361,  0.0361]], grad_fn=<MeanBackward1>)\n",
      "std[:,half]= tensor([[1.0277, 0.9722],\n",
      "        [0.9835, 1.0172],\n",
      "        [0.9884, 1.0117],\n",
      "        [0.9967, 1.0029]], grad_fn=<StdBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_bn1 = bn1(inp)\n",
    "print('out_bn1.size=', out_bn1.size())\n",
    "print('mean= ',out_bn1.mean())\n",
    "print('std= ',out_bn1.std())\n",
    "print('mean[:,half]=', out_bn1.mean(0))\n",
    "print('std[:,half]=', out_bn1.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.4014,   0.3979,  99.9752, 100.0132])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2847,  1.2992, 10.6845, 10.5849])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practise Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2 = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_seq.size: torch.Size([100, 4])\n",
      "out_seq.size: torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "inp_seq = torch.randn((100, 4))*5 + 10\n",
    "test_seq = torch.randn((100, 4))*5 + 10\n",
    "\n",
    "out_seq = seq2(inp_seq)\n",
    "print('inp_seq.size:', inp_seq.size())\n",
    "print('out_seq.size:', out_seq.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_seq = torch.optim.Adam(seq2.parameters(), lr=1e-2)\n",
    "criterion = torch.mean(torch.abs(1 - seq2(inp_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_seq.mean:  tensor([10.5579, 10.1710, 10.0206,  9.2985])\n",
      "inp_seq.std:  tensor([5.6316, 4.9133, 4.7359, 4.5245])\n",
      "\n",
      "criterion: 0.7662103772163391 pred.mean:  [0.3879261016845703, 0.3877398371696472]\n"
     ]
    }
   ],
   "source": [
    "print('inp_seq.mean: ',inp_seq.mean(0))\n",
    "print('inp_seq.std: ',inp_seq.std(0))\n",
    "print()\n",
    "print('criterion:', criterion.mean().item(), 'pred.mean: ',seq2(inp_seq).mean(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion: 0.7662103772163391 pred.mean:  [0.3922105133533478, 0.39067542552948]\n",
      "criterion: 0.7589684128761292 pred.mean:  [0.3953389823436737, 0.39262640476226807]\n",
      "criterion: 0.7521691918373108 pred.mean:  [0.399160236120224, 0.3942054510116577]\n",
      "criterion: 0.7442622184753418 pred.mean:  [0.40493297576904297, 0.39621275663375854]\n",
      "criterion: 0.7359932065010071 pred.mean:  [0.4099179208278656, 0.3980749845504761]\n",
      "criterion: 0.7282418012619019 pred.mean:  [0.4138473868370056, 0.3995427191257477]\n",
      "criterion: 0.7211025953292847 pred.mean:  [0.4176526367664337, 0.40096619725227356]\n",
      "criterion: 0.7148005962371826 pred.mean:  [0.4211721122264862, 0.40232983231544495]\n",
      "criterion: 0.7102056741714478 pred.mean:  [0.42448052763938904, 0.40393170714378357]\n",
      "criterion: 0.7067551612854004 pred.mean:  [0.4274815320968628, 0.40607306361198425]\n",
      "criterion: 0.7033290863037109 pred.mean:  [0.4301227927207947, 0.4088502824306488]\n",
      "criterion: 0.6991634964942932 pred.mean:  [0.43250346183776855, 0.4121593236923218]\n",
      "criterion: 0.6947100758552551 pred.mean:  [0.434682160615921, 0.4155239462852478]\n",
      "criterion: 0.6899051666259766 pred.mean:  [0.4367234408855438, 0.41874778270721436]\n",
      "criterion: 0.6853265166282654 pred.mean:  [0.438645601272583, 0.4219913184642792]\n",
      "criterion: 0.6807544827461243 pred.mean:  [0.4408179819583893, 0.4250721335411072]\n",
      "criterion: 0.6762199401855469 pred.mean:  [0.4435829818248749, 0.4285978078842163]\n",
      "criterion: 0.6706389784812927 pred.mean:  [0.44651180505752563, 0.4315805435180664]\n",
      "criterion: 0.6650477647781372 pred.mean:  [0.44961264729499817, 0.4343206286430359]\n",
      "criterion: 0.6595962643623352 pred.mean:  [0.45266255736351013, 0.4373200237751007]\n",
      "criterion: 0.6542532444000244 pred.mean:  [0.4555797576904297, 0.44044458866119385]\n",
      "criterion: 0.6501041650772095 pred.mean:  [0.4583630859851837, 0.44390231370925903]\n",
      "criterion: 0.6454424262046814 pred.mean:  [0.4611567556858063, 0.44708168506622314]\n",
      "criterion: 0.6409130096435547 pred.mean:  [0.4642137587070465, 0.4500710666179657]\n",
      "criterion: 0.636297345161438 pred.mean:  [0.467955619096756, 0.4530892074108124]\n",
      "criterion: 0.631217360496521 pred.mean:  [0.47207632660865784, 0.4561939239501953]\n",
      "criterion: 0.6263396143913269 pred.mean:  [0.47657543420791626, 0.4592677056789398]\n",
      "criterion: 0.6213743090629578 pred.mean:  [0.4815206229686737, 0.46230781078338623]\n",
      "criterion: 0.6162993907928467 pred.mean:  [0.4869212806224823, 0.46553924679756165]\n",
      "criterion: 0.6108906269073486 pred.mean:  [0.4922936260700226, 0.46878162026405334]\n",
      "criterion: 0.605441689491272 pred.mean:  [0.49778637290000916, 0.4720492660999298]\n",
      "criterion: 0.600335955619812 pred.mean:  [0.5030495524406433, 0.4752853512763977]\n",
      "criterion: 0.5954947471618652 pred.mean:  [0.5082367658615112, 0.47861453890800476]\n",
      "criterion: 0.5908476114273071 pred.mean:  [0.5129820704460144, 0.48275861144065857]\n",
      "criterion: 0.586057722568512 pred.mean:  [0.5173811316490173, 0.4880383014678955]\n",
      "criterion: 0.5805843472480774 pred.mean:  [0.5215044021606445, 0.4931587874889374]\n",
      "criterion: 0.5749526619911194 pred.mean:  [0.5255304574966431, 0.49804070591926575]\n",
      "criterion: 0.5691471695899963 pred.mean:  [0.5296323895454407, 0.5026609301567078]\n",
      "criterion: 0.5631994009017944 pred.mean:  [0.533638060092926, 0.5074245929718018]\n",
      "criterion: 0.5568921566009521 pred.mean:  [0.53765469789505, 0.5123375654220581]\n",
      "criterion: 0.5505709052085876 pred.mean:  [0.5417196154594421, 0.5171103477478027]\n",
      "criterion: 0.5444797277450562 pred.mean:  [0.5456196665763855, 0.5216321349143982]\n",
      "criterion: 0.5387119054794312 pred.mean:  [0.5494788885116577, 0.5264852046966553]\n",
      "criterion: 0.5327037572860718 pred.mean:  [0.5532196164131165, 0.5313962697982788]\n",
      "criterion: 0.5265005826950073 pred.mean:  [0.5575487613677979, 0.5367465019226074]\n",
      "criterion: 0.5195513367652893 pred.mean:  [0.5618732571601868, 0.542721152305603]\n",
      "criterion: 0.5122164487838745 pred.mean:  [0.5662009716033936, 0.5488390326499939]\n",
      "criterion: 0.5047539472579956 pred.mean:  [0.5710334777832031, 0.555122971534729]\n",
      "criterion: 0.49684062600135803 pred.mean:  [0.5761481523513794, 0.56174236536026]\n",
      "criterion: 0.48905301094055176 pred.mean:  [0.5819150805473328, 0.5685393810272217]\n",
      "criterion: 0.48079219460487366 pred.mean:  [0.5879347324371338, 0.5755693316459656]\n",
      "criterion: 0.4723489284515381 pred.mean:  [0.5942246913909912, 0.5832473635673523]\n",
      "criterion: 0.4632992446422577 pred.mean:  [0.6009477376937866, 0.5916522145271301]\n",
      "criterion: 0.4535650908946991 pred.mean:  [0.6087587475776672, 0.6005497574806213]\n",
      "criterion: 0.4429449439048767 pred.mean:  [0.6170670986175537, 0.6101693511009216]\n",
      "criterion: 0.4316035807132721 pred.mean:  [0.6264844536781311, 0.6204972863197327]\n",
      "criterion: 0.419310986995697 pred.mean:  [0.6369428634643555, 0.6313768625259399]\n",
      "criterion: 0.4061538577079773 pred.mean:  [0.6478255391120911, 0.6424942016601562]\n",
      "criterion: 0.3926388919353485 pred.mean:  [0.6592867970466614, 0.654167890548706]\n",
      "criterion: 0.37851500511169434 pred.mean:  [0.6713463664054871, 0.6662891507148743]\n",
      "criterion: 0.36389005184173584 pred.mean:  [0.683634340763092, 0.6785477995872498]\n",
      "criterion: 0.3490124046802521 pred.mean:  [0.6964934468269348, 0.6914569735527039]\n",
      "criterion: 0.3334593176841736 pred.mean:  [0.7094747424125671, 0.7047474384307861]\n",
      "criterion: 0.317623496055603 pred.mean:  [0.7230175137519836, 0.7183568477630615]\n",
      "criterion: 0.3014916777610779 pred.mean:  [0.7368162274360657, 0.7321130633354187]\n",
      "criterion: 0.28539398312568665 pred.mean:  [0.7507529258728027, 0.7460143566131592]\n",
      "criterion: 0.26930317282676697 pred.mean:  [0.7650253772735596, 0.7600587606430054]\n",
      "criterion: 0.2531255781650543 pred.mean:  [0.7798699736595154, 0.7742704153060913]\n",
      "criterion: 0.23672813177108765 pred.mean:  [0.7948001623153687, 0.7886144518852234]\n",
      "criterion: 0.22033487260341644 pred.mean:  [0.809790849685669, 0.803113579750061]\n",
      "criterion: 0.20406584441661835 pred.mean:  [0.8248205780982971, 0.8177842497825623]\n",
      "criterion: 0.18785244226455688 pred.mean:  [0.839871346950531, 0.8326140642166138]\n",
      "criterion: 0.1716328114271164 pred.mean:  [0.854928195476532, 0.8475674390792847]\n",
      "criterion: 0.15541531145572662 pred.mean:  [0.8699779510498047, 0.8626136779785156]\n",
      "criterion: 0.139215350151062 pred.mean:  [0.8850100636482239, 0.877727210521698]\n",
      "criterion: 0.12308266758918762 pred.mean:  [0.9000673890113831, 0.8928858041763306]\n",
      "criterion: 0.10704176872968674 pred.mean:  [0.9151605367660522, 0.9080706238746643]\n",
      "criterion: 0.09104612469673157 pred.mean:  [0.9302724599838257, 0.9232655167579651]\n",
      "criterion: 0.07511023432016373 pred.mean:  [0.9453886151313782, 0.9384822845458984]\n",
      "criterion: 0.05927922576665878 pred.mean:  [0.960572361946106, 0.9537051320075989]\n",
      "criterion: 0.04359925165772438 pred.mean:  [0.9758257269859314, 0.9689213633537292]\n",
      "criterion: 0.027992527931928635 pred.mean:  [0.9911510348320007, 0.9841209650039673]\n",
      "criterion: 0.012564165517687798 pred.mean:  [1.006549596786499, 0.9992937445640564]\n",
      "criterion: 0.005363488104194403 pred.mean:  [1.0198460817337036, 1.0135692358016968]\n",
      "criterion: 0.01727662980556488 pred.mean:  [1.030121088027954, 1.0246939659118652]\n",
      "criterion: 0.028124289587140083 pred.mean:  [1.0375572443008423, 1.0331493616104126]\n",
      "criterion: 0.03630369156599045 pred.mean:  [1.0424898862838745, 1.039270281791687]\n",
      "criterion: 0.04201697185635567 pred.mean:  [1.0452163219451904, 1.0433504581451416]\n",
      "criterion: 0.04554452747106552 pred.mean:  [1.0459959506988525, 1.0456132888793945]\n",
      "criterion: 0.04712928831577301 pred.mean:  [1.0450576543807983, 1.046257495880127]\n",
      "criterion: 0.04699099436402321 pred.mean:  [1.0426043272018433, 1.0454593896865845]\n",
      "criterion: 0.045324601233005524 pred.mean:  [1.0388140678405762, 1.0433772802352905]\n",
      "criterion: 0.04231147840619087 pred.mean:  [1.0338432788848877, 1.0400887727737427]\n",
      "criterion: 0.038110073655843735 pred.mean:  [1.0278613567352295, 1.035728096961975]\n",
      "criterion: 0.03292302042245865 pred.mean:  [1.0210446119308472, 1.0304155349731445]\n",
      "criterion: 0.026891153305768967 pred.mean:  [1.013603925704956, 1.0242279767990112]\n",
      "criterion: 0.020197313278913498 pred.mean:  [1.0059008598327637, 1.0172646045684814]\n",
      "criterion: 0.0129277678206563 pred.mean:  [0.9983562231063843, 1.009585976600647]\n",
      "criterion: 0.005780897568911314 pred.mean:  [0.9932414889335632, 1.0012730360031128]\n",
      "criterion: 0.004505520686507225 pred.mean:  [0.9896062612533569, 0.9926820397377014]\n",
      "criterion: 0.009802673012018204 pred.mean:  [0.9872376322746277, 0.9862166047096252]\n",
      "criterion: 0.014167931862175465 pred.mean:  [0.9863044619560242, 0.9817554950714111]\n",
      "criterion: 0.016736604273319244 pred.mean:  [0.9867869019508362, 0.9791180491447449]\n",
      "criterion: 0.017678242176771164 pred.mean:  [0.9886266589164734, 0.9781084656715393]\n",
      "criterion: 0.017155049368739128 pred.mean:  [0.9917966723442078, 0.9785833954811096]\n",
      "criterion: 0.015279538929462433 pred.mean:  [0.996147096157074, 0.9803508520126343]\n",
      "criterion: 0.012170621193945408 pred.mean:  [1.0016005039215088, 0.9832733273506165]\n",
      "criterion: 0.009541952982544899 pred.mean:  [1.00498366355896, 0.9871956706047058]\n",
      "criterion: 0.00919673964381218 pred.mean:  [1.0065242052078247, 0.9920112490653992]\n",
      "criterion: 0.007466583978384733 pred.mean:  [1.006455421447754, 0.997681200504303]\n",
      "criterion: 0.004541222937405109 pred.mean:  [1.005043625831604, 1.0041687488555908]\n",
      "criterion: 0.0048683276399970055 pred.mean:  [1.0026112794876099, 1.0085784196853638]\n",
      "criterion: 0.005959747824817896 pred.mean:  [0.9995905160903931, 1.011196255683899]\n",
      "criterion: 0.0063996571116149426 pred.mean:  [0.9970755577087402, 1.012274146080017]\n",
      "criterion: 0.007885797880589962 pred.mean:  [0.9963259696960449, 1.0119739770889282]\n",
      "criterion: 0.008092045783996582 pred.mean:  [0.9971780180931091, 1.0104395151138306]\n",
      "criterion: 0.006838828790932894 pred.mean:  [0.999453604221344, 1.0077437162399292]\n",
      "criterion: 0.004458945710211992 pred.mean:  [1.001874327659607, 1.0040096044540405]\n",
      "criterion: 0.003202921710908413 pred.mean:  [1.0032960176467896, 0.9993200898170471]\n",
      "criterion: 0.0020719498861581087 pred.mean:  [1.0032967329025269, 0.996512234210968]\n",
      "criterion: 0.003524394938722253 pred.mean:  [1.0018773078918457, 0.995113730430603]\n",
      "criterion: 0.003476785495877266 pred.mean:  [0.9991623163223267, 0.9951590895652771]\n",
      "criterion: 0.0029032407328486443 pred.mean:  [0.9982278943061829, 0.9965825080871582]\n",
      "criterion: 0.002670855727046728 pred.mean:  [0.9987307190895081, 0.9991509914398193]\n",
      "criterion: 0.0012594601139426231 pred.mean:  [0.999931275844574, 1.0022602081298828]\n",
      "criterion: 0.001779734157025814 pred.mean:  [1.0012853145599365, 1.0044171810150146]\n",
      "criterion: 0.003014052752405405 pred.mean:  [1.001185417175293, 1.0052083730697632]\n",
      "criterion: 0.003312029642984271 pred.mean:  [1.0000497102737427, 1.004539966583252]\n",
      "criterion: 0.0025846350472420454 pred.mean:  [0.9990530610084534, 1.0024828910827637]\n",
      "criterion: 0.0017319765174761415 pred.mean:  [0.9994753003120422, 0.9991877675056458]\n",
      "criterion: 0.0009923758916556835 pred.mean:  [1.000126838684082, 0.9976222515106201]\n",
      "criterion: 0.0015703407116234303 pred.mean:  [1.0006251335144043, 0.9976591467857361]\n",
      "criterion: 0.001502792234532535 pred.mean:  [0.9995716214179993, 0.9990416765213013]\n",
      "criterion: 0.0009895822731778026 pred.mean:  [0.999071478843689, 1.0009218454360962]\n",
      "criterion: 0.0013208204181864858 pred.mean:  [0.9994348883628845, 1.002070665359497]\n",
      "criterion: 0.0013447675155475736 pred.mean:  [1.0010231733322144, 1.0017207860946655]\n",
      "criterion: 0.0015930739464238286 pred.mean:  [1.0017632246017456, 0.9999755024909973]\n",
      "criterion: 0.000950547750107944 pred.mean:  [1.0009270906448364, 0.9984847903251648]\n",
      "criterion: 0.0017205080948770046 pred.mean:  [0.9986863732337952, 0.9978610873222351]\n",
      "criterion: 0.0021231023129075766 pred.mean:  [0.997714638710022, 0.9982212781906128]\n",
      "criterion: 0.0020323104690760374 pred.mean:  [0.9983278512954712, 0.9999784827232361]\n",
      "criterion: 0.0017435336485505104 pred.mean:  [1.0003259181976318, 1.001450777053833]\n",
      "criterion: 0.0014316582819446921 pred.mean:  [1.0017149448394775, 1.0015949010849]\n",
      "criterion: 0.0017332425341010094 pred.mean:  [1.0014832019805908, 1.0008039474487305]\n",
      "criterion: 0.0019108093110844493 pred.mean:  [1.0007704496383667, 0.9998003244400024]\n",
      "criterion: 0.0009293904877267778 pred.mean:  [0.9998600482940674, 0.9992424249649048]\n",
      "criterion: 0.0009206366376020014 pred.mean:  [0.9990677833557129, 1.0001846551895142]\n",
      "criterion: 0.0009204447269439697 pred.mean:  [0.998860239982605, 1.0008330345153809]\n",
      "criterion: 0.001369407749734819 pred.mean:  [1.0000747442245483, 1.0009245872497559]\n",
      "criterion: 0.0014012933243066072 pred.mean:  [1.001231074333191, 1.0001353025436401]\n",
      "criterion: 0.0011416679481044412 pred.mean:  [1.000779628753662, 0.9993931651115417]\n",
      "criterion: 0.0008473381167277694 pred.mean:  [0.9993312358856201, 0.9996584057807922]\n",
      "criterion: 0.000981408404186368 pred.mean:  [0.9995149374008179, 1.0000154972076416]\n",
      "criterion: 0.0006658667116425931 pred.mean:  [1.001038908958435, 1.00019109249115]\n",
      "criterion: 0.0013641631230711937 pred.mean:  [1.0009334087371826, 1.0003199577331543]\n",
      "criterion: 0.001391872763633728 pred.mean:  [0.9993741512298584, 1.00034761428833]\n",
      "criterion: 0.0004885825328528881 pred.mean:  [0.9993773698806763, 0.9988991618156433]\n",
      "criterion: 0.0012510818196460605 pred.mean:  [1.0008342266082764, 0.9981241822242737]\n",
      "criterion: 0.0014556339010596275 pred.mean:  [1.0006918907165527, 0.9983718395233154]\n",
      "criterion: 0.0011601140722632408 pred.mean:  [0.9991203546524048, 1.0000654458999634]\n",
      "criterion: 0.0009666615515016019 pred.mean:  [0.9991496801376343, 1.0016241073608398]\n",
      "criterion: 0.0012372437631711364 pred.mean:  [1.000609278678894, 1.0015511512756348]\n",
      "criterion: 0.0010982186067849398 pred.mean:  [1.0004900693893433, 1.0001649856567383]\n",
      "criterion: 0.0006691497401334345 pred.mean:  [0.9989596009254456, 0.9986491203308105]\n",
      "criterion: 0.0012945595663040876 pred.mean:  [0.9990054965019226, 0.9984028339385986]\n",
      "criterion: 0.0015309175942093134 pred.mean:  [1.0004607439041138, 0.9991225600242615]\n",
      "criterion: 0.0007442474598065019 pred.mean:  [1.000385046005249, 1.0008580684661865]\n",
      "criterion: 0.0008956778328865767 pred.mean:  [0.998911440372467, 1.0016859769821167]\n",
      "criterion: 0.0015382770216092467 pred.mean:  [0.9989904761314392, 1.0013418197631836]\n",
      "criterion: 0.0011757579632103443 pred.mean:  [1.0004582405090332, 0.9995680451393127]\n",
      "criterion: 0.0005822303937748075 pred.mean:  [1.0004104375839233, 0.9987027049064636]\n",
      "criterion: 0.0008539554546587169 pred.mean:  [0.9989789724349976, 0.9993893504142761]\n",
      "criterion: 0.000969953543972224 pred.mean:  [0.9990787506103516, 1.0005661249160767]\n",
      "criterion: 0.000743507465813309 pred.mean:  [1.00054931640625, 1.0001604557037354]\n",
      "criterion: 0.000817153777461499 pred.mean:  [1.0005748271942139, 0.9997062087059021]\n",
      "criterion: 0.00043428182834759355 pred.mean:  [0.9992241859436035, 1.000759482383728]\n",
      "criterion: 0.0009644970414228737 pred.mean:  [0.9993811845779419, 1.0009477138519287]\n",
      "criterion: 0.0007866472005844116 pred.mean:  [1.0008352994918823, 0.9997177124023438]\n",
      "criterion: 0.0006904834299348295 pred.mean:  [1.0008039474487305, 0.999075710773468]\n",
      "criterion: 0.0008744040387682617 pred.mean:  [0.9994155764579773, 0.9998688697814941]\n",
      "criterion: 0.0008721247431822121 pred.mean:  [0.9994720220565796, 1.000614047050476]\n",
      "criterion: 0.000571105454582721 pred.mean:  [1.0008766651153564, 0.9998261332511902]\n",
      "criterion: 0.0010769080836325884 pred.mean:  [1.0007870197296143, 0.9992612600326538]\n",
      "criterion: 0.0007968431455083191 pred.mean:  [0.9993588924407959, 0.9999204277992249]\n",
      "criterion: 0.0008953875512816012 pred.mean:  [0.9993941783905029, 1.0005154609680176]\n",
      "criterion: 0.0007483708905056119 pred.mean:  [1.0007669925689697, 1.0003774166107178]\n",
      "criterion: 0.0009223425295203924 pred.mean:  [1.0006881952285767, 1.000046968460083]\n",
      "criterion: 0.000832247722428292 pred.mean:  [0.9992824792861938, 0.9998375773429871]\n",
      "criterion: 0.0007845634245313704 pred.mean:  [0.9993256330490112, 0.9997367858886719]\n",
      "criterion: 0.0007227688911370933 pred.mean:  [1.0006672143936157, 0.9998537302017212]\n",
      "criterion: 0.000836711551528424 pred.mean:  [1.000545859336853, 1.000107765197754]\n",
      "criterion: 0.0006964841741137207 pred.mean:  [0.9991648197174072, 1.0003077983856201]\n",
      "criterion: 0.0009229060960933566 pred.mean:  [0.9992466568946838, 1.0001587867736816]\n",
      "criterion: 0.0008611098164692521 pred.mean:  [1.0006389617919922, 0.9998745918273926]\n",
      "criterion: 0.0006863126181997359 pred.mean:  [1.000625491142273, 0.9997983574867249]\n",
      "criterion: 0.0006139760953374207 pred.mean:  [0.9992995262145996, 1.0000613927841187]\n",
      "criterion: 0.0009270405862480402 pred.mean:  [0.999420166015625, 1.0001474618911743]\n",
      "criterion: 0.0008300069021061063 pred.mean:  [1.000836968421936, 1.0000736713409424]\n",
      "criterion: 0.0007238301914185286 pred.mean:  [1.0008035898208618, 0.9999768733978271]\n",
      "criterion: 0.000666614156216383 pred.mean:  [0.9994699954986572, 1.0000416040420532]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    opt_seq.zero_grad()\n",
    "    criterion = torch.mean(torch.abs(1 - seq2(inp_seq)))\n",
    "    criterion.backward()\n",
    "    opt_seq.step()\n",
    "    print('criterion:', criterion.mean().item(), 'pred.mean: ',seq2(inp_seq).mean(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro to PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
