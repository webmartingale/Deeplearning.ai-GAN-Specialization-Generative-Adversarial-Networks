{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1k6Y9afpxL6"
   },
   "source": [
    "# Intro\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a very powerful machine learning framework. Central to PyTorch are [tensors](https://pytorch.org/docs/stable/tensors.html), a generalization of matrices to higher ranks. One intuitive example of a tensor is an image with three color channels: A 3-channel (red, green, blue) image which is 64 pixels wide and 64 pixels tall is a $3\\times64\\times64$ tensor. You can access the PyTorch framework by writing `import torch` near the top of your code, along with all of your other import statements.\n",
    "\n",
    "This guide will help introduce you to the functionality of PyTorch, but don't worry too much about memorizing it: the assignments will link to relevant documentation where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwp6T5ZMteDC"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvXp0rlPBqdQ"
   },
   "source": [
    "# Why PyTorch?\n",
    "\n",
    "One important question worth asking is, why is PyTorch being used for this course? There is a great breakdown by [the Gradient](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) looking at the state of machine learning frameworks today. In part, as highlighted by the article, PyTorch is generally more pythonic than alternative frameworks, easier to debug, and is the most-used language in machine learning research by a large and growing margin. While PyTorch's primary alternative, Tensorflow, has attempted to integrate many of PyTorch's features, Tensorflow's implementations come with some inherent limitations highlighted in the article.\n",
    "\n",
    "Notably, while PyTorch's industry usage has grown, Tensorflow is still (for now) a slight favorite in industry. In practice, the features that make PyTorch attractive for research also make it attractive for education, and the general trend of machine learning research and practice to PyTorch makes it the more proactive choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCgwdP20r1yX"
   },
   "source": [
    "# Tensor Properties\n",
    "One way to create tensors from a list or an array is to use `torch.Tensor`. It'll be used to set up examples in this notebook, but you'll never need to use it in the course - in fact, if you find yourself needing it, that's probably not the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0hgYekGsxlB"
   },
   "outputs": [],
   "source": [
    "example_tensor = torch.Tensor(\n",
    "    [\n",
    "     [[1, 2], [3, 4]], \n",
    "     [[5, 6], [7, 8]], \n",
    "     [[9, 0], [1, 2]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dO4C2oft7zq"
   },
   "source": [
    "You can view the tensor in the notebook by simple printing it out (though some larger tensors will be cut off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "U2FKEzeYuEOX",
    "outputId": "dfa12ff7-afd1-4737-a669-54f36b4209dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[9., 0.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUwlmUngw-VR"
   },
   "source": [
    "## Tensor Properties: Device\n",
    "\n",
    "One important property is the device of the tensor - throughout this notebook you'll be sticking to tensors which are on the CPU. However, throughout the course you'll also be using tensors on GPU (that is, a graphics card which will be provided for you to use for the course). To view the device of the tensor, all you need to write is `example_tensor.device`. To move a tensor to a new device, you can write `new_tensor = example_tensor.to(device)` where device will be either `cpu` or `cuda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R7SF44_Vw9h0",
    "outputId": "57f90e38-f9e1-4115-8f27-ebe651d5b2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkfySyFduHQi"
   },
   "source": [
    "## Tensor Properties: Shape\n",
    "\n",
    "And you can get the number of elements in each dimension by printing out the tensor's shape, using `example_tensor.shape`, something you're likely familiar with if you've used numpy. For example, this tensor is a $3\\times2\\times2$ tensor, since it has 3 elements, each of which are $2\\times2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DKmfzpOBun0t",
    "outputId": "883009b6-7300-4329-f9ec-df99cc36d846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aL954xmAuq4b"
   },
   "source": [
    "You can also get the size of a particular dimension $n$ using `example_tensor.shape[n]` or equivalently `example_tensor.size(n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7IKy3BB8uqBo",
    "outputId": "7fac1275-132f-4d2b-bf63-73065a2aea6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape[0] = 3\n",
      "size(1) = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"shape[0] =\", example_tensor.shape[0])\n",
    "print(\"size(1) =\", example_tensor.size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pzzG8bav5rl"
   },
   "source": [
    "Finally, it is sometimes useful to get the number of dimensions (rank) or the number of elements, which you can do as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l_j9qTwyv41-",
    "outputId": "5921cbd1-19a2-4543-9488-3f72c0cb4970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank = 3\n",
      "Number of elements = 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank =\", len(example_tensor.shape))\n",
    "print(\"Number of elements =\", example_tensor.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gibyKQJQzLkm"
   },
   "source": [
    "# Indexing Tensors\n",
    "\n",
    "As with numpy, you can access specific elements or subsets of elements of a tensor. To access the $n$-th element, you can simply write `example_tensor[n]` - as with Python in general, these dimensions are 0-indexed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F87bFA5SzNz7",
    "outputId": "1b0a8381-6fd8-40b4-a5c8-88cc80029f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CegGw5wzpGa"
   },
   "source": [
    "In addition, if you want to access the $j$-th dimension of the $i$-th example, you can write `example_tensor[i, j]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bl1JSZcRz0xn",
    "outputId": "7f98e47b-66cb-4927-b784-7e4bcb9eb687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyQRCRIa4NaY"
   },
   "source": [
    "Note that if you'd like to get a Python scalar value from a tensor, you can use `example_scalar.item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e56KSJOq4YOE",
    "outputId": "29e1fd13-32df-40c5-e558-3193fa5da629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZdMEQfu0A7h"
   },
   "source": [
    "In addition, you can index into the ith element of a column by using `x[:, i]`. For example, if you want the top-left element of each element in `example_tensor`, which is the `0, 0` element of each matrix, you can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x2cFxJx50eGH",
    "outputId": "e66eade9-4b4b-4c7a-ea99-a83195d10541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-rTBP-1whd2"
   },
   "source": [
    "# Initializing Tensors\n",
    "\n",
    "There are many ways to create new tensors in PyTorch, but in this course, the most important ones are: \n",
    "\n",
    "[`torch.ones_like`](https://pytorch.org/docs/master/generated/torch.ones_like.html): creates a tensor of all ones with the same shape and device as `example_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "g7gbs4AnwlIo",
    "outputId": "b0c67ed9-e33f-47d6-d95c-e53bc4f90dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aIbSlaJy9Z0"
   },
   "source": [
    "[`torch.zeros_like`](https://pytorch.org/docs/master/generated/torch.zeros_like.html): creates a tensor of all zeros with the same shape and device as `example_tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "X4cWQduzzCd8",
    "outputId": "dbc8a5fa-8db1-4f6d-e38e-d1deb982ff36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsOmgS1izDS_"
   },
   "source": [
    "[`torch.randn_like`](https://pytorch.org/docs/stable/generated/torch.randn_like.html): creates a tensor with every element sampled from a [Normal (or Gaussian) distribution](https://en.wikipedia.org/wiki/Normal_distribution) with the same shape and device as `example_tensor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2hto51IazDow",
    "outputId": "cb62a68a-6171-4d1e-eb9b-f31784464aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9978,  0.4220],\n",
       "         [ 1.1297,  1.1127]],\n",
       "\n",
       "        [[-0.4906, -0.5921],\n",
       "         [-0.6182, -0.2926]],\n",
       "\n",
       "        [[ 0.3970,  1.2238],\n",
       "         [-0.3999, -2.3067]]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXp0i5Cf6AGj"
   },
   "source": [
    "Sometimes (though less often than you'd expect), you might need to initialize a tensor knowing only the shape and device, without a tensor for reference for `ones_like` or `randn_like`. In this case, you can create a $2x2$ tensor as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RZRqt3-S6cUZ",
    "outputId": "7bef97cc-a303-4200-c0f8-ef9bf3cb4996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1872,  0.3411],\n",
       "        [ 0.1447, -0.9064]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 2, device='cpu') # Alternatively, for a GPU tensor, you'd use device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTkmDwVsrM6R"
   },
   "source": [
    "# Basic Functions\n",
    "\n",
    "There are a number of basic functions that you should know to use PyTorch - if you're familiar with numpy, all commonly-used functions exist in PyTorch, usually with the same name. You can perform element-wise multiplication / division by a scalar $c$ by simply writing `c * example_tensor`, and element-wise addition / subtraction by a scalar by writing `example_tensor + c`\n",
    "\n",
    "Note that most operations are not in-place in PyTorch, which means that they don't change the original variable's data (However, you can reassign the same variable name to the changed data if you'd like, such as `example_tensor = example_tensor + 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "FpfwOUdopsF_",
    "outputId": "32347400-2e6a-40c6-e6f1-21e6aacde795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -8.,  -6.],\n",
       "         [ -4.,  -2.]],\n",
       "\n",
       "        [[  0.,   2.],\n",
       "         [  4.,   6.]],\n",
       "\n",
       "        [[  8., -10.],\n",
       "         [ -8.,  -6.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example_tensor - 5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uciZnx4b3UjX"
   },
   "source": [
    "You can calculate the mean or standard deviation of a tensor using [`example_tensor.mean()`](https://pytorch.org/docs/stable/generated/torch.mean.html) or [`example_tensor.std()`](https://pytorch.org/docs/stable/generated/torch.std.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0ELXUKG7329z",
    "outputId": "720dd190-7dd4-43f1-e53c-cba4263eb2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(4.)\n",
      "Stdev: tensor(2.9848)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", example_tensor.mean())\n",
    "print(\"Stdev:\", example_tensor.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QsyTRym32SX"
   },
   "source": [
    "You might also want to find the mean or standard deviation along a particular dimension. To do this you can simple pass the number corresponding to that dimension to the function. For example, if you want to get the average $2\\times2$ matrix of the $3\\times2\\times2$ `example_tensor` you can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eCJl3Im25B9k",
    "outputId": "4bd9decd-579e-462c-bde1-ee8d9d1b2061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 2.6667],\n",
       "        [3.6667, 4.6667]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.mean(0)\n",
    "\n",
    "# Equivalently, you could also write:\n",
    "# example_tensor.mean(dim=0)\n",
    "# example_tensor.mean(axis=0)\n",
    "# torch.mean(example_tensor, 0)\n",
    "# torch.mean(example_tensor, dim=0)\n",
    "# torch.mean(example_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb-_5ubc8t97"
   },
   "source": [
    "PyTorch has many other powerful functions but these should be all of PyTorch functions you need for this course outside of its neural network module (`torch.nn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtWjExD69JEs"
   },
   "source": [
    "# PyTorch Neural Network Module (`torch.nn`)\n",
    "\n",
    "PyTorch has a lot of powerful classes in its `torch.nn` module (Usually, imported as simply `nn`). These classes allow you to create a new function which transforms a tensor in specific way, often retaining information when called multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYrgloYo_slC"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyCPVmTD_kkl"
   },
   "source": [
    "## `nn.Linear`\n",
    "\n",
    "To create a linear layer, you need to pass it the number of input dimensions and the number of output dimensions. The linear object initialized as `nn.Linear(10, 2)` will take in a $n\\times10$ matrix and return an $n\\times2$ matrix, where all $n$ elements have had the same linear transformation performed. For example, you can initialize a linear layer which performs the operation $Ax + b$, where $A$ and $b$ are initialized randomly when you generate the [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pNPaHPo89VrN",
    "outputId": "c14dc316-ae68-49d3-a8eb-8ad6e1464f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1228, -0.5515],\n",
       "        [-0.4051, -0.3493],\n",
       "        [ 0.6284, -0.4660]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 2)\n",
    "example_input = torch.randn(3, 10)\n",
    "example_output = linear(example_input)\n",
    "example_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGNULkJR_mzn"
   },
   "source": [
    "## `nn.ReLU`\n",
    "\n",
    "[`nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) will create an object that, when receiving a tensor, will perform a ReLU activation function. This will be reviewed further in lecture, but in essence, a ReLU non-linearity sets all negative numbers in a tensor to zero. In general, the simplest neural networks are composed of series of linear transformations, each followed by activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nGxVFS3nBASc",
    "outputId": "d5f57584-1bad-4803-ba8c-b69881db4a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1228, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.6284, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu_output = relu(example_output)\n",
    "relu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzfOEZ03AJzA"
   },
   "source": [
    "## `nn.BatchNorm1d`\n",
    "\n",
    "[`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) is a normalization technique that will rescale a batch of $n$ inputs to have a consistent mean and standard deviation between batches.  \n",
    "\n",
    "As indicated by the `1d` in its name, this is for situations where you expects a set of inputs, where each of them is a flat list of numbers. In other words, each input is a vector, not a matrix or higher-dimensional tensor. For a set of images, each of which is a higher-dimensional tensor, you'd use [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), discussed later on this page.\n",
    "\n",
    "`nn.BatchNorm1d` takes an argument of the number of input dimensions of each object in the batch (the size of each example vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "O4tYsi9-G9vM",
    "outputId": "ba61d37c-a8af-4663-fcc2-1691c6d241de",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4692,  0.0000],\n",
       "        [-0.9207,  0.0000],\n",
       "        [ 1.3899,  0.0000]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchnorm = nn.BatchNorm1d(2)\n",
    "batchnorm_output = batchnorm(relu_output)\n",
    "batchnorm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMZewDz9Idr1"
   },
   "source": [
    "## `nn.Sequential`\n",
    "\n",
    "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) creates a single operation that performs a sequence of operations. For example, you can write a neural network layer with a batch normalization as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "R3GhASjyJt3N",
    "outputId": "3ef779ca-a17b-42fd-f2e5-fbb5fdc60b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "tensor([[ 1.7303,  0.5612,  1.5421,  1.4326,  0.2131],\n",
      "        [ 1.2737,  0.4196,  2.6722, -0.9903,  1.8938],\n",
      "        [-0.1214, -0.2092,  2.7572, -0.3132,  1.5605],\n",
      "        [ 0.9103,  1.8051,  2.1779,  0.0294,  1.4851],\n",
      "        [ 1.2489,  0.3082,  1.4790,  0.2106, -0.7151]])\n",
      "output: \n",
      "tensor([[1.2664, 1.0569],\n",
      "        [0.1012, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.6109, 0.0000],\n",
      "        [0.0000, 1.2557]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp_layer = nn.Sequential(\n",
    "    nn.Linear(5, 2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "test_example = torch.randn(5,5) + 1\n",
    "print(\"input: \")\n",
    "print(test_example)\n",
    "print(\"output: \")\n",
    "print(mlp_layer(test_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SToQiSv5K5Yb"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "One of the most important aspects of essentially any machine learning framework is its automatic differentiation library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4GZFCZ0QqI1"
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "To create an optimizer in PyTorch, you'll need to use the `torch.optim` module, often imported as `optim`. [`optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) corresponds to the Adam optimizer. To create an optimizer object, you'll need to pass it the parameters to be optimized and the learning rate, `lr`, as well as any other parameters specific to the optimizer.\n",
    "\n",
    "For all `nn` objects, you can access their parameters as a list using their `parameters()` method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcCbs35K4wY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "adam_opt = optim.Adam(mlp_layer.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BsPFZu2M0Xx"
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "A (basic) training step in PyTorch consists of four basic parts:\n",
    "\n",
    "\n",
    "1.   Set all of the gradients to zero using `opt.zero_grad()`\n",
    "2.   Calculate the loss, `loss`\n",
    "3.   Calculate the gradients with respect to the loss using `loss.backward()`\n",
    "4.   Update the parameters being optimized using `opt.step()`\n",
    "\n",
    "That might look like the following code (and you'll notice that if you run it several times, the loss goes down):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40549442172050476\n"
     ]
    }
   ],
   "source": [
    "print(mlp_layer(train_example).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zm6lPx4sOJht",
    "outputId": "c21672bd-a306-42ab-face-9a299511a059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=  0.008653788827359676\n",
      "mean pred=  1.001314640045166\n"
     ]
    }
   ],
   "source": [
    "train_example = torch.randn(100,5) + 1\n",
    "adam_opt.zero_grad()\n",
    "\n",
    "# We'll use a simple loss function of mean distance from 1\n",
    "# torch.abs takes the absolute value of a tensor\n",
    "cur_loss = torch.abs(1 - mlp_layer(train_example)).mean()\n",
    "\n",
    "cur_loss.backward()\n",
    "adam_opt.step()\n",
    "print('loss= ',cur_loss.item())\n",
    "print('mean pred= ', mlp_layer(train_example).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "tensor([0.9263, 2.6936])\n",
      "tensor([3.3188, 3.8906])\n",
      "Parameter containing:\n",
      "tensor([-0.0184,  0.0134], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9978, 1.0048], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "bn2 = mlp_layer[1]\n",
    "print(bn2.momentum)\n",
    "print(bn2.running_mean)\n",
    "print(bn2.running_var)\n",
    "print(bn2.weight)\n",
    "print(bn2.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDjhZBCeTc6o"
   },
   "source": [
    "## `requires_grad_()`\n",
    "\n",
    "You can also tell PyTorch that it needs to calculate the gradient with respect to a tensor that you created by saying `example_tensor.requires_grad_()`, which will change it in-place. This means that even if PyTorch wouldn't normally store a grad for that particular tensor, it will for that specified tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mB22ovHyUEvH"
   },
   "source": [
    "## `with torch.no_grad():`\n",
    "\n",
    "PyTorch will usually calculate the gradients as it proceeds through a set of operations on tensors. This can often take up unnecessary computations and memory, especially if you're performing an evaluation. However, you can wrap a piece of code with `with torch.no_grad()` to prevent the gradients from being calculated in a piece of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kowb1M425CE_"
   },
   "source": [
    "\n",
    "## `detach():`\n",
    "\n",
    "Sometimes, you want to calculate and use a tensor's value without calculating its gradients. For example, if you have two models, A and B, and you want to directly optimize the parameters of A with respect to the output of B, without calculating the gradients through B, then you could feed the detached output of B to A. There are many reasons you might want to do this, including efficiency or cyclical dependencies (i.e. A depends on B depends on A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9HY2wgKLOr-"
   },
   "source": [
    "# New `nn` Classes\n",
    "\n",
    "You can also create new classes which extend the `nn` module. For these classes, all class attributes, as in `self.layer` or `self.param` will automatically treated as parameters if they are themselves `nn` objects or if they are tensors wrapped in `nn.Parameter` which are initialized with the class. \n",
    "\n",
    "The `__init__` function defines what will happen when the object is created. The first line of the init function of a class, for example, `WellNamedClass`, needs to be `super(WellNamedClass, self).__init__()`. \n",
    "\n",
    "The `forward` function defines what runs if you create that object `model` and pass it a tensor `x`, as in `model(x)`. If you choose the function signature, `(self, x)`, then each call of the forward function, gets two pieces of information: `self`, which is a reference to the object with which you can access all of its parameters, and `x`, which is the current tensor for which you'd like to return `y`.\n",
    "\n",
    "One class might look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOip473tQs-d"
   },
   "outputs": [],
   "source": [
    "class ExampleModule(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(ExampleModule, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_dims)\n",
    "        self.exponent = nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # This is the notation for element-wise exponentiation, \n",
    "        # which matches python in general\n",
    "        x = x ** self.exponent \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4CUFH_GS5UY"
   },
   "source": [
    "And you can view its parameters as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YuelIiE4S3KR",
    "outputId": "27a52620-ca40-4dc8-dff5-4f3a56ba0e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor(1., requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0391,  0.2376,  0.3002, -0.0059,  0.1202,  0.0787, -0.1480, -0.0032,\n",
       "          -0.2241,  0.2305],\n",
       "         [ 0.1697,  0.1022,  0.1738, -0.2234, -0.2029, -0.2930, -0.0189,  0.1619,\n",
       "          -0.0473, -0.1139]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3145,  0.3061], requires_grad=True)]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model = ExampleModule(10, 2)\n",
    "list(example_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F7E1wKN5tez"
   },
   "source": [
    "And you can print out their names too, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "dYTuTDsQ5pnY",
    "outputId": "6635a493-7318-4688-bd18-bfba41d43e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exponent',\n",
       "  Parameter containing:\n",
       "  tensor(1., requires_grad=True)),\n",
       " ('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0391,  0.2376,  0.3002, -0.0059,  0.1202,  0.0787, -0.1480, -0.0032,\n",
       "           -0.2241,  0.2305],\n",
       "          [ 0.1697,  0.1022,  0.1738, -0.2234, -0.2029, -0.2930, -0.0189,  0.1619,\n",
       "           -0.0473, -0.1139]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.3145,  0.3061], requires_grad=True))]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example_model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWPoIqX2UsaH"
   },
   "source": [
    "And here's an example of the class in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7NXwbg5tUroC",
    "outputId": "0836e447-7c37-464e-b196-048ae0a0cc73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7832,  0.2343],\n",
       "        [ 0.7357, -0.6448]], grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 10)\n",
    "example_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ocol8DABScy"
   },
   "source": [
    "# 2D Operations\n",
    "\n",
    "You won't need these for the first lesson, and the theory behind each of these will be reviewed more in later lectures, but here is a quick reference: \n",
    "\n",
    "\n",
    "*   2D convolutions: [`nn.Conv2d`](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html) requires the number of input and output channels, as well as the kernel size.\n",
    "*   2D transposed convolutions (aka deconvolutions): [`nn.ConvTranspose2d`](https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html) also requires the number of input and output channels, as well as the kernel size\n",
    "*   2D batch normalization: [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) requires the number of input dimensions\n",
    "*   Resizing images: [`nn.Upsample`](https://pytorch.org/docs/master/generated/torch.nn.Upsample.html) requires the final size or a scale factor. Alternatively, [`nn.functional.interpolate`](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.interpolate) takes the same arguments. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import\n",
    "* make tensor from list\n",
    "    * check shape\n",
    "    * check device\n",
    "* indexing\n",
    "* init ones_like, randn_like\n",
    "* use in basic functions (add, mult, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = torch.tensor([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list[0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]]])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = torch.ones_like(t_list)\n",
    "t_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_zeros = torch.zeros_like(t_list)\n",
    "t_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1, 13],\n",
       "         [59, 30]],\n",
       "\n",
       "        [[75, 55],\n",
       "         [92,  9]],\n",
       "\n",
       "        [[67, 91],\n",
       "         [36,  8]]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randint = torch.randint_like(t_list, low=0, high=99)\n",
    "t_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float = t_list.float()\n",
    "t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9035, 0.8126],\n",
       "         [0.2175, 0.3822]],\n",
       "\n",
       "        [[0.7538, 0.2252],\n",
       "         [0.3084, 0.2604]],\n",
       "\n",
       "        [[0.6566, 0.0969],\n",
       "         [0.7106, 0.8755]]])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rand = torch.rand_like(t_list_float)\n",
    "t_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1852,  0.1782],\n",
       "         [-1.7686, -0.3846]],\n",
       "\n",
       "        [[ 0.3064,  1.0465],\n",
       "         [ 0.9214,  1.4667]],\n",
       "\n",
       "        [[ 0.3442, -1.1185],\n",
       "         [ 0.0454, -0.1407]]])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randn = torch.randn_like(t_list_float)\n",
    "t_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  4.],\n",
       "         [ 6.,  8.]],\n",
       "\n",
       "        [[10., 12.],\n",
       "         [14., 16.]],\n",
       "\n",
       "        [[18., 20.],\n",
       "         [22., 24.]]])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9]],\n",
       "\n",
       "        [[10, 11],\n",
       "         [12, 13]]])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float + t_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  3.],\n",
       "         [ 4.,  5.]],\n",
       "\n",
       "        [[ 6.,  7.],\n",
       "         [ 8.,  9.]],\n",
       "\n",
       "        [[10., 11.],\n",
       "         [12., 13.]]])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float + t_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9035,  2.8126],\n",
       "         [ 3.2175,  4.3822]],\n",
       "\n",
       "        [[ 5.7538,  6.2252],\n",
       "         [ 7.3084,  8.2604]],\n",
       "\n",
       "        [[ 9.6566, 10.0969],\n",
       "         [11.7106, 12.8755]]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  2,  15],\n",
       "         [ 62,  34]],\n",
       "\n",
       "        [[ 80,  61],\n",
       "         [ 99,  17]],\n",
       "\n",
       "        [[ 76, 101],\n",
       "         [ 47,  20]]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1852,  2.1782],\n",
       "         [ 1.2314,  3.6154]],\n",
       "\n",
       "        [[ 5.3064,  7.0465],\n",
       "         [ 7.9214,  9.4667]],\n",
       "\n",
       "        [[ 9.3442,  8.8815],\n",
       "         [11.0454, 11.8593]]])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list + t_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   4.],\n",
       "         [  9.,  16.]],\n",
       "\n",
       "        [[ 25.,  36.],\n",
       "         [ 49.,  64.]],\n",
       "\n",
       "        [[ 81., 100.],\n",
       "         [121., 144.]]])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list * t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -1.1852,   0.3565],\n",
       "         [ -5.3058,  -1.5382]],\n",
       "\n",
       "        [[  1.5321,   6.2789],\n",
       "         [  6.4500,  11.7333]],\n",
       "\n",
       "        [[  3.0982, -11.1852],\n",
       "         [  0.4996,  -1.6879]]])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list * t_randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1,   4],\n",
       "         [  9,  16]],\n",
       "\n",
       "        [[ 25,  36],\n",
       "         [ 49,  64]],\n",
       "\n",
       "        [[ 81, 100],\n",
       "         [121, 144]]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   4.],\n",
       "         [  9.,  16.]],\n",
       "\n",
       "        [[ 25.,  36.],\n",
       "         [ 49.,  64.]],\n",
       "\n",
       "        [[ 81., 100.],\n",
       "         [121., 144.]]])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_zeros **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [1, 1]]])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9, 9],\n",
       "         [9, 9]],\n",
       "\n",
       "        [[9, 9],\n",
       "         [9, 9]],\n",
       "\n",
       "        [[9, 9],\n",
       "         [9, 9]]])"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_ones+2) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6639,  4.7447],\n",
       "         [ 0.0535,  2.6097]],\n",
       "\n",
       "        [[ 5.3195,  9.2811],\n",
       "         [ 8.5348, 12.0178]],\n",
       "\n",
       "        [[ 5.4955,  0.7770],\n",
       "         [ 4.1838,  3.4571]]])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_randn+2) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4048e+00, 3.1766e-02],\n",
       "         [3.1279e+00, 1.4788e-01]],\n",
       "\n",
       "        [[9.3889e-02, 1.0951e+00],\n",
       "         [8.4904e-01, 2.1511e+00]],\n",
       "\n",
       "        [[1.1850e-01, 1.2511e+00],\n",
       "         [2.0632e-03, 1.9785e-02]]])"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_randn) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5000)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5000)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_zeros.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5169)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rand.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(44.6667)"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randint.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0241)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6056)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2950)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9670)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_randn.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 7.5000])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_list_float.mean([0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = nn.BatchNorm1d(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4, 2])"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.cat((torch.randn((1000,2,2))*2 + 4, torch.randn((1000,2,2))*10 + 1000), dim=1)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=  tensor(502.0768)\n",
      "std=  tensor(498.1198)\n",
      "var=  tensor(248123.3750)\n",
      "mean[:,half]= tensor([[   3.9727,    4.0349],\n",
      "        [   4.0958,    4.0500],\n",
      "        [1000.2912, 1000.2211],\n",
      "        [1000.1827,  999.7654]])\n",
      "std[:,half]= tensor([[ 2.0737,  2.0205],\n",
      "        [ 1.9628,  1.9578],\n",
      "        [10.1904,  9.6542],\n",
      "        [ 9.6412,  9.7556]])\n",
      "var[:,half]= tensor([[  4.3004,   4.0824],\n",
      "        [  3.8526,   3.8330],\n",
      "        [103.8436,  93.2029],\n",
      "        [ 92.9519,  95.1726]])\n"
     ]
    }
   ],
   "source": [
    "print('mean= ',inp.mean())\n",
    "print('std= ',inp.std())\n",
    "print('var= ',inp.var())\n",
    "print('mean[:,half]=', inp.mean(0))\n",
    "print('std[:,half]=', inp.std(0))\n",
    "print('var[:,half]=', inp.var(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_bn1.size= torch.Size([1000, 4, 2])\n",
      "mean=  tensor(-2.9802e-08, grad_fn=<MeanBackward0>)\n",
      "std=  tensor(1.0001, grad_fn=<StdBackward0>)\n",
      "mean[:,half]= tensor([[-0.0152,  0.0152],\n",
      "        [ 0.0117, -0.0117],\n",
      "        [ 0.0035, -0.0035],\n",
      "        [ 0.0215, -0.0215]], grad_fn=<MeanBackward1>)\n",
      "std[:,half]= tensor([[1.0133, 0.9873],\n",
      "        [1.0017, 0.9992],\n",
      "        [1.0272, 0.9731],\n",
      "        [0.9943, 1.0062]], grad_fn=<StdBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out_bn1 = bn1(inp)\n",
    "print('out_bn1.size=', out_bn1.size())\n",
    "print('mean= ',out_bn1.mean())\n",
    "print('std= ',out_bn1.std())\n",
    "print('mean[:,half]=', out_bn1.mean(0))\n",
    "print('std[:,half]=', out_bn1.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.4004,   0.4073, 100.0256,  99.9974])"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3190,  1.2841, 10.7475, 10.3059])"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practise Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2 = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_seq.size: torch.Size([100, 4])\n",
      "out_seq.size: torch.Size([100, 2])\n"
     ]
    }
   ],
   "source": [
    "inp_seq = torch.randn((100, 4))*5 + 10\n",
    "test_seq = torch.randn((100, 4))*5 + 10\n",
    "\n",
    "out_seq = seq2(inp_seq)\n",
    "print('inp_seq.size:', inp_seq.size())\n",
    "print('out_seq.size:', out_seq.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_seq = torch.optim.Adam(seq2.parameters(), lr=1e-2)\n",
    "criterion = torch.mean(torch.abs(1 - seq2(inp_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_seq.mean:  tensor([ 9.6964,  9.9637, 10.0301, 10.1222])\n",
      "inp_seq.std:  tensor([4.9715, 4.7236, 6.0874, 4.7249])\n",
      "\n",
      "criterion: 0.7421380877494812 pred.mean:  [0.40517953038215637, 0.4210793375968933]\n"
     ]
    }
   ],
   "source": [
    "print('inp_seq.mean: ',inp_seq.mean(0))\n",
    "print('inp_seq.std: ',inp_seq.std(0))\n",
    "print()\n",
    "print('criterion:', criterion.mean().item(), 'pred.mean: ',seq2(inp_seq).mean(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion: 0.7421380877494812 pred.mean:  [0.4075961410999298, 0.42210766673088074]\n",
      "criterion: 0.7373782992362976 pred.mean:  [0.40993422269821167, 0.422648161649704]\n",
      "criterion: 0.7331397533416748 pred.mean:  [0.41202449798583984, 0.4232085049152374]\n",
      "criterion: 0.7288660407066345 pred.mean:  [0.4136117696762085, 0.423598974943161]\n",
      "criterion: 0.7247567176818848 pred.mean:  [0.41488978266716003, 0.4240996837615967]\n",
      "criterion: 0.7207810878753662 pred.mean:  [0.41593414545059204, 0.4243142604827881]\n",
      "criterion: 0.716713547706604 pred.mean:  [0.41736680269241333, 0.42413246631622314]\n",
      "criterion: 0.7127713561058044 pred.mean:  [0.4188031256198883, 0.42415642738342285]\n",
      "criterion: 0.7089537978172302 pred.mean:  [0.42057907581329346, 0.4243384599685669]\n",
      "criterion: 0.7047342658042908 pred.mean:  [0.42286187410354614, 0.4250100255012512]\n",
      "criterion: 0.7004141211509705 pred.mean:  [0.4251701235771179, 0.42640969157218933]\n",
      "criterion: 0.6962131261825562 pred.mean:  [0.42761513590812683, 0.4283776879310608]\n",
      "criterion: 0.6922237873077393 pred.mean:  [0.4298786222934723, 0.4309349060058594]\n",
      "criterion: 0.6881653070449829 pred.mean:  [0.4320361018180847, 0.43356648087501526]\n",
      "criterion: 0.684343695640564 pred.mean:  [0.43446651101112366, 0.4362817704677582]\n",
      "criterion: 0.6802908182144165 pred.mean:  [0.43671754002571106, 0.439014732837677]\n",
      "criterion: 0.6763545870780945 pred.mean:  [0.438833087682724, 0.4421229660511017]\n",
      "criterion: 0.6722614169120789 pred.mean:  [0.4407268166542053, 0.44535964727401733]\n",
      "criterion: 0.6683728098869324 pred.mean:  [0.4423516094684601, 0.4485569894313812]\n",
      "criterion: 0.6648169755935669 pred.mean:  [0.4437495470046997, 0.4520800709724426]\n",
      "criterion: 0.6616111993789673 pred.mean:  [0.4452299475669861, 0.4561929404735565]\n",
      "criterion: 0.6582273840904236 pred.mean:  [0.44695529341697693, 0.46053123474121094]\n",
      "criterion: 0.6544919013977051 pred.mean:  [0.4489901661872864, 0.46464934945106506]\n",
      "criterion: 0.6505517363548279 pred.mean:  [0.45130661129951477, 0.46934473514556885]\n",
      "criterion: 0.6461547017097473 pred.mean:  [0.4537029564380646, 0.4742721617221832]\n",
      "criterion: 0.6417184472084045 pred.mean:  [0.4560266137123108, 0.479182630777359]\n",
      "criterion: 0.63773113489151 pred.mean:  [0.4582825005054474, 0.4838332235813141]\n",
      "criterion: 0.6337087750434875 pred.mean:  [0.4604748785495758, 0.48829734325408936]\n",
      "criterion: 0.6294609904289246 pred.mean:  [0.46261778473854065, 0.49230775237083435]\n",
      "criterion: 0.6252841949462891 pred.mean:  [0.4651713967323303, 0.4964214563369751]\n",
      "criterion: 0.6211395859718323 pred.mean:  [0.46786782145500183, 0.5005049705505371]\n",
      "criterion: 0.6167311668395996 pred.mean:  [0.47064587473869324, 0.5045365691184998]\n",
      "criterion: 0.6121880412101746 pred.mean:  [0.4734024405479431, 0.5088291764259338]\n",
      "criterion: 0.6076509952545166 pred.mean:  [0.47650593519210815, 0.5133839249610901]\n",
      "criterion: 0.6030052304267883 pred.mean:  [0.47971102595329285, 0.5180919170379639]\n",
      "criterion: 0.5981741547584534 pred.mean:  [0.48326531052589417, 0.5229209661483765]\n",
      "criterion: 0.5930755734443665 pred.mean:  [0.48701250553131104, 0.5278255343437195]\n",
      "criterion: 0.5877598524093628 pred.mean:  [0.4910203516483307, 0.5330252647399902]\n",
      "criterion: 0.5820568203926086 pred.mean:  [0.4953077733516693, 0.5384665131568909]\n",
      "criterion: 0.5762062072753906 pred.mean:  [0.5001229047775269, 0.5440021753311157]\n",
      "criterion: 0.5700573325157166 pred.mean:  [0.505479633808136, 0.5494491457939148]\n",
      "criterion: 0.5637026429176331 pred.mean:  [0.5113894939422607, 0.5549160242080688]\n",
      "criterion: 0.5570094585418701 pred.mean:  [0.5175937414169312, 0.560482919216156]\n",
      "criterion: 0.5501092076301575 pred.mean:  [0.5242325067520142, 0.5669282674789429]\n",
      "criterion: 0.5425325036048889 pred.mean:  [0.5310236215591431, 0.5737651586532593]\n",
      "criterion: 0.5347095727920532 pred.mean:  [0.5379981994628906, 0.5807526111602783]\n",
      "criterion: 0.5266841053962708 pred.mean:  [0.5449454188346863, 0.5880663394927979]\n",
      "criterion: 0.5183380246162415 pred.mean:  [0.5519957542419434, 0.5954749584197998]\n",
      "criterion: 0.5098032355308533 pred.mean:  [0.5591635704040527, 0.6029559969902039]\n",
      "criterion: 0.5011222958564758 pred.mean:  [0.5667725205421448, 0.6106926202774048]\n",
      "criterion: 0.492036372423172 pred.mean:  [0.574942409992218, 0.6187495589256287]\n",
      "criterion: 0.48234936594963074 pred.mean:  [0.5838217735290527, 0.6270591616630554]\n",
      "criterion: 0.4720824062824249 pred.mean:  [0.5929156541824341, 0.6357496380805969]\n",
      "criterion: 0.461406409740448 pred.mean:  [0.602705180644989, 0.6451427936553955]\n",
      "criterion: 0.44984573125839233 pred.mean:  [0.6128769516944885, 0.6548919677734375]\n",
      "criterion: 0.4377550482749939 pred.mean:  [0.6234018206596375, 0.6647007465362549]\n",
      "criterion: 0.42531707882881165 pred.mean:  [0.6342041492462158, 0.6748256087303162]\n",
      "criterion: 0.4124431610107422 pred.mean:  [0.645770788192749, 0.685222327709198]\n",
      "criterion: 0.3989429771900177 pred.mean:  [0.6583033204078674, 0.6956612467765808]\n",
      "criterion: 0.38488587737083435 pred.mean:  [0.6714478135108948, 0.7060336470603943]\n",
      "criterion: 0.3704361617565155 pred.mean:  [0.6849313974380493, 0.7163450717926025]\n",
      "criterion: 0.35574522614479065 pred.mean:  [0.6984659433364868, 0.7270370721817017]\n",
      "criterion: 0.3407851755619049 pred.mean:  [0.7120645046234131, 0.7393145561218262]\n",
      "criterion: 0.3249867260456085 pred.mean:  [0.7259663939476013, 0.7518576979637146]\n",
      "criterion: 0.3088904321193695 pred.mean:  [0.7402798533439636, 0.7647356390953064]\n",
      "criterion: 0.29240578413009644 pred.mean:  [0.7546768188476562, 0.7777965664863586]\n",
      "criterion: 0.27578258514404297 pred.mean:  [0.7691345810890198, 0.7910292148590088]\n",
      "criterion: 0.2590029239654541 pred.mean:  [0.783664345741272, 0.8046489953994751]\n",
      "criterion: 0.24201203882694244 pred.mean:  [0.7982746958732605, 0.8182454109191895]\n",
      "criterion: 0.2249973714351654 pred.mean:  [0.8129726648330688, 0.8318138122558594]\n",
      "criterion: 0.2080022096633911 pred.mean:  [0.8277631402015686, 0.845350980758667]\n",
      "criterion: 0.19107520580291748 pred.mean:  [0.8426772952079773, 0.8588535189628601]\n",
      "criterion: 0.1741807907819748 pred.mean:  [0.857685387134552, 0.8723191618919373]\n",
      "criterion: 0.1573193222284317 pred.mean:  [0.8727607727050781, 0.8857864141464233]\n",
      "criterion: 0.14049935340881348 pred.mean:  [0.8878815174102783, 0.8992489576339722]\n",
      "criterion: 0.12372949719429016 pred.mean:  [0.9030290246009827, 0.9127006530761719]\n",
      "criterion: 0.10701929777860641 pred.mean:  [0.9181876182556152, 0.9260949492454529]\n",
      "criterion: 0.09037832915782928 pred.mean:  [0.9333427548408508, 0.9394329786300659]\n",
      "criterion: 0.07383604347705841 pred.mean:  [0.9485123157501221, 0.9527165293693542]\n",
      "criterion: 0.057368531823158264 pred.mean:  [0.963681161403656, 0.9659042358398438]\n",
      "criterion: 0.040992315858602524 pred.mean:  [0.9788655042648315, 0.9790027737617493]\n",
      "criterion: 0.02479463815689087 pred.mean:  [0.9941315650939941, 0.9918903112411499]\n",
      "criterion: 0.008961365558207035 pred.mean:  [1.0095809698104858, 1.004407286643982]\n",
      "criterion: 0.008054866455495358 pred.mean:  [1.0222784280776978, 1.0129605531692505]\n",
      "criterion: 0.02041042409837246 pred.mean:  [1.0320090055465698, 1.0193970203399658]\n",
      "criterion: 0.030261583626270294 pred.mean:  [1.0391120910644531, 1.02421236038208]\n",
      "criterion: 0.03741108253598213 pred.mean:  [1.0438473224639893, 1.0275673866271973]\n",
      "criterion: 0.042154937982559204 pred.mean:  [1.0464870929718018, 1.0296084880828857]\n",
      "criterion: 0.0447700172662735 pred.mean:  [1.047235369682312, 1.030465841293335]\n",
      "criterion: 0.04549608379602432 pred.mean:  [1.0463122129440308, 1.0302577018737793]\n",
      "criterion: 0.044551439583301544 pred.mean:  [1.0439114570617676, 1.0290390253067017]\n",
      "criterion: 0.042142972350120544 pred.mean:  [1.0402051210403442, 1.0268620252609253]\n",
      "criterion: 0.03845040872693062 pred.mean:  [1.035378098487854, 1.0237250328063965]\n",
      "criterion: 0.03362036868929863 pred.mean:  [1.0295599699020386, 1.0196799039840698]\n",
      "criterion: 0.027779215946793556 pred.mean:  [1.0228965282440186, 1.014681339263916]\n",
      "criterion: 0.021032821387052536 pred.mean:  [1.0154850482940674, 1.0087417364120483]\n",
      "criterion: 0.013462635688483715 pred.mean:  [1.0074114799499512, 1.0019699335098267]\n",
      "criterion: 0.0051681711338460445 pred.mean:  [0.9988141059875488, 0.9942001104354858]\n",
      "criterion: 0.003942701034247875 pred.mean:  [0.9928916692733765, 0.9888438582420349]\n",
      "criterion: 0.010387211106717587 pred.mean:  [0.9890029430389404, 0.985474169254303]\n",
      "criterion: 0.014777803793549538 pred.mean:  [0.9867845773696899, 0.9838742017745972]\n",
      "criterion: 0.017213694751262665 pred.mean:  [0.9860270023345947, 0.983802318572998]\n",
      "criterion: 0.017900746315717697 pred.mean:  [0.9865764379501343, 0.9849987030029297]\n",
      "criterion: 0.017049813643097878 pred.mean:  [0.9883962273597717, 0.9871877431869507]\n",
      "criterion: 0.014853161759674549 pred.mean:  [0.9914149641990662, 0.9901278614997864]\n",
      "criterion: 0.011455731466412544 pred.mean:  [0.9955014586448669, 0.9936493039131165]\n",
      "criterion: 0.006998927798122168 pred.mean:  [1.000725269317627, 0.997649610042572]\n",
      "criterion: 0.002637091325595975 pred.mean:  [1.005008339881897, 1.0018943548202515]\n",
      "criterion: 0.003647621488198638 pred.mean:  [1.0071988105773926, 1.004289984703064]\n",
      "criterion: 0.006845827680081129 pred.mean:  [1.0075016021728516, 1.0056242942810059]\n",
      "criterion: 0.008204171434044838 pred.mean:  [1.0061652660369873, 1.0060480833053589]\n",
      "criterion: 0.007944989018142223 pred.mean:  [1.003407597541809, 1.0056507587432861]\n",
      "criterion: 0.006354657467454672 pred.mean:  [0.9997602701187134, 1.0045113563537598]\n",
      "criterion: 0.004125827457755804 pred.mean:  [0.9965931177139282, 1.002652883529663]\n",
      "criterion: 0.0036537351552397013 pred.mean:  [0.9950866103172302, 1.0000492334365845]\n",
      "criterion: 0.0033300563227385283 pred.mean:  [0.9946746230125427, 0.9974504113197327]\n",
      "criterion: 0.004884379915893078 pred.mean:  [0.9951831102371216, 0.9963920712471008]\n",
      "criterion: 0.004912978038191795 pred.mean:  [0.99668288230896, 0.9968587756156921]\n",
      "criterion: 0.0036278932821005583 pred.mean:  [0.9995468854904175, 0.9985899329185486]\n",
      "criterion: 0.0015751969767734408 pred.mean:  [1.002556324005127, 1.0009783506393433]\n",
      "criterion: 0.0017709961393848062 pred.mean:  [1.0036975145339966, 1.0006990432739258]\n",
      "criterion: 0.003097356064245105 pred.mean:  [1.0031139850616455, 1.0001592636108398]\n",
      "criterion: 0.0030305131804198027 pred.mean:  [1.0009994506835938, 0.9997680187225342]\n",
      "criterion: 0.0014656850835308433 pred.mean:  [0.9975560903549194, 0.9996556043624878]\n",
      "criterion: 0.0014823338715359569 pred.mean:  [0.9960503578186035, 1.000375747680664]\n",
      "criterion: 0.0026964948046952486 pred.mean:  [0.9962665438652039, 1.0004929304122925]\n",
      "criterion: 0.0023317623417824507 pred.mean:  [0.9980142116546631, 0.9996764659881592]\n",
      "criterion: 0.0015100223245099187 pred.mean:  [1.001063585281372, 0.9995233416557312]\n",
      "criterion: 0.0012098642764613032 pred.mean:  [1.0025677680969238, 1.0000678300857544]\n",
      "criterion: 0.0013420316390693188 pred.mean:  [1.0023800134658813, 1.0000213384628296]\n",
      "criterion: 0.0023119673132896423 pred.mean:  [1.0008355379104614, 0.9997344017028809]\n",
      "criterion: 0.0022499924525618553 pred.mean:  [0.9991335272789001, 0.9994254112243652]\n",
      "criterion: 0.0014667954528704286 pred.mean:  [0.9990746974945068, 0.9994432330131531]\n",
      "criterion: 0.0012907013297080994 pred.mean:  [0.9992978572845459, 1.0018833875656128]\n",
      "criterion: 0.0016892215935513377 pred.mean:  [0.9999909400939941, 1.0026702880859375]\n",
      "criterion: 0.0024512673262506723 pred.mean:  [1.0006481409072876, 1.0019798278808594]\n",
      "criterion: 0.002321306150406599 pred.mean:  [1.001086950302124, 1.0004438161849976]\n",
      "criterion: 0.0011260169558227062 pred.mean:  [0.99993896484375, 0.9987667798995972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion: 0.0017336183227598667 pred.mean:  [0.9988706707954407, 0.9985620379447937]\n",
      "criterion: 0.0021119459997862577 pred.mean:  [0.9985890984535217, 0.998909056186676]\n",
      "criterion: 0.001994856633245945 pred.mean:  [0.9996663928031921, 0.9995136857032776]\n",
      "criterion: 0.0016423366032540798 pred.mean:  [1.0007625818252563, 1.0003514289855957]\n",
      "criterion: 0.0013548418646678329 pred.mean:  [1.0013483762741089, 1.0009125471115112]\n",
      "criterion: 0.0021338651422411203 pred.mean:  [1.0011281967163086, 1.0011255741119385]\n",
      "criterion: 0.0022717765532433987 pred.mean:  [1.0005227327346802, 1.0007771253585815]\n",
      "criterion: 0.0009900698205456138 pred.mean:  [0.9995995163917542, 0.9981950521469116]\n",
      "criterion: 0.0018821811536327004 pred.mean:  [0.998954713344574, 0.9979064464569092]\n",
      "criterion: 0.002650756621733308 pred.mean:  [0.9987514615058899, 0.9987931251525879]\n",
      "criterion: 0.001976428320631385 pred.mean:  [0.999422013759613, 1.0001202821731567]\n",
      "criterion: 0.0011602378217503428 pred.mean:  [1.0003129243850708, 1.0010783672332764]\n",
      "criterion: 0.001602258998900652 pred.mean:  [1.0009584426879883, 1.0010273456573486]\n",
      "criterion: 0.0017270997632294893 pred.mean:  [0.9999532103538513, 1.0006918907165527]\n",
      "criterion: 0.0016656764782965183 pred.mean:  [0.9991090297698975, 1.0000983476638794]\n",
      "criterion: 0.0007942858501337469 pred.mean:  [0.999776303768158, 0.9995624423027039]\n",
      "criterion: 0.001253996742889285 pred.mean:  [1.0005381107330322, 0.9992737770080566]\n",
      "criterion: 0.0017777946777641773 pred.mean:  [0.9997963905334473, 0.9992084503173828]\n",
      "criterion: 0.0017166743054986 pred.mean:  [0.9994131326675415, 0.9994436502456665]\n",
      "criterion: 0.0010863078059628606 pred.mean:  [0.9996085166931152, 0.9999514222145081]\n",
      "criterion: 0.0009164917282760143 pred.mean:  [1.0003265142440796, 1.0006566047668457]\n",
      "criterion: 0.0017452738247811794 pred.mean:  [1.0008149147033691, 1.0009962320327759]\n",
      "criterion: 0.0015914252726361156 pred.mean:  [1.0006141662597656, 1.0007567405700684]\n",
      "criterion: 0.0007693213410675526 pred.mean:  [0.999502420425415, 0.9986246228218079]\n",
      "criterion: 0.0011914765927940607 pred.mean:  [0.9990147948265076, 0.9984290599822998]\n",
      "criterion: 0.0016998749924823642 pred.mean:  [0.9999876618385315, 0.9990836977958679]\n",
      "criterion: 0.0016820793971419334 pred.mean:  [1.0008978843688965, 1.0000677108764648]\n",
      "criterion: 0.0007923695375211537 pred.mean:  [1.0001134872436523, 1.0007091760635376]\n",
      "criterion: 0.001272933790460229 pred.mean:  [0.9992766380310059, 1.000992774963379]\n",
      "criterion: 0.0017455711495131254 pred.mean:  [1.0001243352890015, 1.0009514093399048]\n",
      "criterion: 0.0016538632335141301 pred.mean:  [1.0008575916290283, 1.0006165504455566]\n",
      "criterion: 0.0009508293587714434 pred.mean:  [0.9999198317527771, 0.9997172355651855]\n",
      "criterion: 0.0012700834777206182 pred.mean:  [0.9990733861923218, 0.999055027961731]\n",
      "criterion: 0.001674295635893941 pred.mean:  [0.9999067783355713, 0.9987579584121704]\n",
      "criterion: 0.0013584909029304981 pred.mean:  [1.0007867813110352, 0.9990413784980774]\n",
      "criterion: 0.0009203717345371842 pred.mean:  [1.0001757144927979, 1.0012335777282715]\n",
      "criterion: 0.0011376002803444862 pred.mean:  [0.9994648694992065, 1.0014647245407104]\n",
      "criterion: 0.0013719910057261586 pred.mean:  [1.0000056028366089, 1.0007834434509277]\n",
      "criterion: 0.0012905329931527376 pred.mean:  [1.0005253553390503, 0.999870240688324]\n",
      "criterion: 0.0006572601268999279 pred.mean:  [1.0002576112747192, 0.9994942545890808]\n",
      "criterion: 0.0011925754370167851 pred.mean:  [0.9996302723884583, 0.9994537234306335]\n",
      "criterion: 0.0019361084559932351 pred.mean:  [0.9993540048599243, 0.9995672106742859]\n",
      "criterion: 0.001759771374054253 pred.mean:  [0.9996536374092102, 0.999769926071167]\n",
      "criterion: 0.0007690039346925914 pred.mean:  [1.0004091262817383, 1.00015389919281]\n",
      "criterion: 0.0010510316351428628 pred.mean:  [1.0003771781921387, 1.0005511045455933]\n",
      "criterion: 0.001697344472631812 pred.mean:  [1.0000560283660889, 1.0007072687149048]\n",
      "criterion: 0.0014349069679155946 pred.mean:  [0.9997338056564331, 1.0005438327789307]\n",
      "criterion: 0.0011891680769622326 pred.mean:  [0.9994753003120422, 0.999837338924408]\n",
      "criterion: 0.001347802928648889 pred.mean:  [0.9994057416915894, 0.9991487264633179]\n",
      "criterion: 0.001383618451654911 pred.mean:  [1.0009742975234985, 0.9988340139389038]\n",
      "criterion: 0.0016924417577683926 pred.mean:  [1.0018659830093384, 0.9992159008979797]\n",
      "criterion: 0.00137607310898602 pred.mean:  [1.0012325048446655, 1.001879096031189]\n",
      "criterion: 0.0015808242605999112 pred.mean:  [0.9991394281387329, 1.0019010305404663]\n",
      "criterion: 0.0016456320881843567 pred.mean:  [0.9988793134689331, 1.0007747411727905]\n",
      "criterion: 0.001730876276269555 pred.mean:  [0.9999036192893982, 0.9994590878486633]\n",
      "criterion: 0.0010607981821522117 pred.mean:  [1.0008600950241089, 0.9990735054016113]\n",
      "criterion: 0.0010171181056648493 pred.mean:  [1.0006864070892334, 1.0004686117172241]\n",
      "criterion: 0.0016936075408011675 pred.mean:  [1.0001728534698486, 1.0012787580490112]\n",
      "criterion: 0.0012877973495051265 pred.mean:  [0.999319851398468, 1.0009610652923584]\n",
      "criterion: 0.001608554390259087 pred.mean:  [0.9987130761146545, 0.9990409016609192]\n",
      "criterion: 0.0019110074499621987 pred.mean:  [0.9984915852546692, 0.9989492297172546]\n",
      "criterion: 0.0018843859434127808 pred.mean:  [0.9991750121116638, 0.9998043179512024]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    opt_seq.zero_grad()\n",
    "    criterion = torch.mean(torch.abs(1 - seq2(inp_seq)))\n",
    "    criterion.backward()\n",
    "    opt_seq.step()\n",
    "    print('criterion:', criterion.mean().item(), 'pred.mean: ',seq2(inp_seq).mean(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro to PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
